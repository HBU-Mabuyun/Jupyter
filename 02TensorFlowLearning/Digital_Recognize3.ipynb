{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow手工搭建CNN回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在利用Tensorflow手工搭建CNN的时候，我们主要经历这么几个步骤：\n",
    "\n",
    "    1、定义训练样本和label，这里仍然是采用批处理的方式。\n",
    "    \n",
    "    2、采用两层卷积层和池化层。\n",
    "    \n",
    "    3、最后跟一层全连接层，并在最后一层加入dropout\n",
    "    \n",
    "    4、激活函数使用Relu，具体原因可以理解为防止梯度消失等问题吧。\n",
    "    \n",
    "    5、loss选择的还是log损失，这和问题是一个分类问题有关。\n",
    "    \n",
    "    6、优化没有选在传统的gradient-descent了，而是选择使用AdaDelta，基本原理估计还是GD，猜想是对学习率等内容做了调整。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "呃，现在问题是，我们发现这样如果要搭一个很多层的网络的话，一层一层去配太麻烦，而且万一漏了，要一层层检查就很尴尬。\n",
    "\n",
    "因此，需要多tensorflow做一个封装，不需要自己去搭建，告诉代码我要几层，他们怎么样就好了。\n",
    "\n",
    "keras就是实现这个封装的包，它的底层是用tensorflow来实现的。\n",
    "\n",
    "那么，更新之后的神经网络格式是这样的：\n",
    "\n",
    "    1、keras实现cnn\n",
    "    \n",
    "    2、2层网络\n",
    "    \n",
    "    3、卷积（&池化）之后，加入规范层\n",
    "    \n",
    "    4、使用RELU激活函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载相关的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Conv2D\n",
    "from keras.layers import MaxPool2D,Flatten,Dropout,ZeroPadding2D,BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.models import save_model,load_model\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 乱序&分割\n",
    "\n",
    "将原数据集进行乱序，并把特征和labels进行分割。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**乱序**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.as_matrix()\n",
    "\n",
    "df=None\n",
    "\n",
    "# 乱序\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分割特征并改变格式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=data[:,1:]\n",
    "# 把1*784的数据转化成28*28的格式\n",
    "x_train=x_train.reshape(data.shape[0],28,28,1).astype('float32')\n",
    "x_train=x_train/255.0\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分割labels并one-hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分割得到labels，并利用numpy进行one-hot\n",
    "y_train=np_utils.to_categorical(data[:,0],10).astype('float32')\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置神经网络参数\n",
    "\n",
    "这里设置三个参数：\n",
    "\n",
    "    1、batch大小：64\n",
    "    \n",
    "    2、卷积滤镜个数：32\n",
    "    \n",
    "    3、池化核大小：2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch-size\n",
    "batch_size=64\n",
    "\n",
    "# 卷积滤镜\n",
    "n_filters=32\n",
    "\n",
    "# 池化核\n",
    "pool_size=(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "\n",
    "这是最核心的地方，利用keras我们能够很方便的定义一个3层的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第一层:卷积池化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_net=Sequential()\n",
    "\n",
    "# 第一层\n",
    "cnn_net.add(Conv2D(32,kernel_size=(3,3),strides=(1,1),input_shape=(28,28,1)))\n",
    "cnn_net.add(Activation('relu'))\n",
    "cnn_net.add(BatchNormalization(epsilon=1e-6,axis=1))\n",
    "cnn_net.add(MaxPool2D(pool_size=pool_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第二层：卷积池化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_net.add(ZeroPadding2D((1,1)))\n",
    "cnn_net.add(Conv2D(48,kernel_size=(3,3)))\n",
    "cnn_net.add(Activation('relu'))\n",
    "cnn_net.add(BatchNormalization(epsilon=1e-6,axis=1))\n",
    "cnn_net.add(MaxPool2D(pool_size=pool_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第三层：卷积池化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_net.add(ZeroPadding2D((1,1)))\n",
    "cnn_net.add(Conv2D(64,kernel_size=(2,2)))\n",
    "cnn_net.add(Activation('relu'))\n",
    "cnn_net.add(BatchNormalization(epsilon=1e-6,axis=1))\n",
    "cnn_net.add(MaxPool2D(pool_size=pool_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第四层：全连接**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_net.add(Dropout(0.25))\n",
    "cnn_net.add(Flatten())\n",
    "\n",
    "cnn_net.add(Dense(3168))\n",
    "cnn_net.add(Activation('relu'))\n",
    "\n",
    "cnn_net.add(Dense(10))\n",
    "cnn_net.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看模型结构\n",
    "\n",
    "由于绘图的功能一直搞不定，勉强用这个看一下把"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        104       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 48)        13872     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 13, 13, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 48)        52        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 48)          0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 64)          28        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3168)              1827936   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3168)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                31690     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,886,354\n",
      "Trainable params: 1,886,262\n",
      "Non-trainable params: 92\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/50\n",
      "33600/33600 [==============================] - 80s 2ms/step - loss: 0.2255 - acc: 0.9332 - val_loss: 0.0701 - val_acc: 0.9801\n",
      "Epoch 2/50\n",
      "33600/33600 [==============================] - 80s 2ms/step - loss: 0.0731 - acc: 0.9774 - val_loss: 0.0685 - val_acc: 0.9781\n",
      "Epoch 3/50\n",
      "33600/33600 [==============================] - 77s 2ms/step - loss: 0.0533 - acc: 0.9838 - val_loss: 0.0638 - val_acc: 0.9832\n",
      "Epoch 4/50\n",
      "33600/33600 [==============================] - 82s 2ms/step - loss: 0.0424 - acc: 0.9869 - val_loss: 0.0443 - val_acc: 0.9877\n",
      "Epoch 5/50\n",
      "33600/33600 [==============================] - 83s 2ms/step - loss: 0.0389 - acc: 0.9881 - val_loss: 0.0377 - val_acc: 0.9886\n",
      "Epoch 6/50\n",
      "33600/33600 [==============================] - 80s 2ms/step - loss: 0.0300 - acc: 0.9906 - val_loss: 0.0477 - val_acc: 0.9865\n",
      "Epoch 7/50\n",
      "33600/33600 [==============================] - 80s 2ms/step - loss: 0.0314 - acc: 0.9905 - val_loss: 0.0461 - val_acc: 0.9875\n",
      "Epoch 8/50\n",
      "33600/33600 [==============================] - 81s 2ms/step - loss: 0.0245 - acc: 0.9918 - val_loss: 0.0500 - val_acc: 0.9887\n",
      "Epoch 9/50\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0279 - acc: 0.9913 - val_loss: 0.0378 - val_acc: 0.9890\n",
      "Epoch 10/50\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0576 - val_acc: 0.9868\n",
      "Epoch 11/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0225 - acc: 0.9934 - val_loss: 0.0420 - val_acc: 0.9902\n",
      "Epoch 12/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0178 - acc: 0.9947 - val_loss: 0.0422 - val_acc: 0.9888\n",
      "Epoch 13/50\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0185 - acc: 0.9945 - val_loss: 0.0415 - val_acc: 0.9895\n",
      "Epoch 14/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0147 - acc: 0.9956 - val_loss: 0.0383 - val_acc: 0.9911\n",
      "Epoch 15/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.0466 - val_acc: 0.9899\n",
      "Epoch 16/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0129 - acc: 0.9963 - val_loss: 0.0484 - val_acc: 0.9885\n",
      "Epoch 17/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.0443 - val_acc: 0.9901\n",
      "Epoch 18/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0119 - acc: 0.9966 - val_loss: 0.0428 - val_acc: 0.9904\n",
      "Epoch 19/50\n",
      "33600/33600 [==============================] - 80s 2ms/step - loss: 0.0147 - acc: 0.9957 - val_loss: 0.0452 - val_acc: 0.9913\n",
      "Epoch 20/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0116 - acc: 0.9962 - val_loss: 0.0520 - val_acc: 0.9895\n",
      "Epoch 21/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0412 - val_acc: 0.9904\n",
      "Epoch 22/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0104 - acc: 0.9970 - val_loss: 0.0444 - val_acc: 0.9893\n",
      "Epoch 23/50\n",
      "33600/33600 [==============================] - 77s 2ms/step - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0451 - val_acc: 0.9914\n",
      "Epoch 24/50\n",
      "33600/33600 [==============================] - 80s 2ms/step - loss: 0.0118 - acc: 0.9971 - val_loss: 0.0413 - val_acc: 0.9913\n",
      "Epoch 25/50\n",
      "33600/33600 [==============================] - 80s 2ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.0480 - val_acc: 0.9911\n",
      "Epoch 26/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0122 - acc: 0.9962 - val_loss: 0.0474 - val_acc: 0.9907\n",
      "Epoch 27/50\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0737 - val_acc: 0.9875\n",
      "Epoch 28/50\n",
      "33600/33600 [==============================] - 82s 2ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0591 - val_acc: 0.9893\n",
      "Epoch 29/50\n",
      "33600/33600 [==============================] - 87s 3ms/step - loss: 0.0082 - acc: 0.9979 - val_loss: 0.0399 - val_acc: 0.9921\n",
      "Epoch 30/50\n",
      "33600/33600 [==============================] - 87s 3ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0484 - val_acc: 0.9912\n",
      "Epoch 31/50\n",
      "33600/33600 [==============================] - 84s 3ms/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0424 - val_acc: 0.9904\n",
      "Epoch 32/50\n",
      "33600/33600 [==============================] - 91s 3ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0485 - val_acc: 0.9913\n",
      "Epoch 33/50\n",
      "33600/33600 [==============================] - 82s 2ms/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0502 - val_acc: 0.9904\n",
      "Epoch 34/50\n",
      "33600/33600 [==============================] - 78s 2ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0477 - val_acc: 0.9902\n",
      "Epoch 35/50\n",
      "33600/33600 [==============================] - 79s 2ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0441 - val_acc: 0.9908\n",
      "Epoch 36/50\n",
      "33600/33600 [==============================] - 84s 3ms/step - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0499 - val_acc: 0.9904\n",
      "Epoch 37/50\n",
      "33600/33600 [==============================] - 83s 2ms/step - loss: 0.0051 - acc: 0.9989 - val_loss: 0.0465 - val_acc: 0.9913\n",
      "Epoch 38/50\n",
      "33600/33600 [==============================] - 82s 2ms/step - loss: 0.0081 - acc: 0.9978 - val_loss: 0.0533 - val_acc: 0.9910\n",
      "Epoch 39/50\n",
      "33600/33600 [==============================] - 81s 2ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0566 - val_acc: 0.9911\n",
      "Epoch 40/50\n",
      "33600/33600 [==============================] - 81s 2ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0490 - val_acc: 0.9917\n",
      "Epoch 41/50\n",
      "33600/33600 [==============================] - 84s 3ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0460 - val_acc: 0.9908\n",
      "Epoch 42/50\n",
      "33600/33600 [==============================] - 86s 3ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0492 - val_acc: 0.9904\n",
      "Epoch 43/50\n",
      "33600/33600 [==============================] - 85s 3ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0500 - val_acc: 0.9893\n",
      "Epoch 44/50\n",
      "33600/33600 [==============================] - 85s 3ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0454 - val_acc: 0.9906\n",
      "Epoch 45/50\n",
      "33600/33600 [==============================] - 84s 3ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0570 - val_acc: 0.9907\n",
      "Epoch 46/50\n",
      "33600/33600 [==============================] - 83s 2ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0498 - val_acc: 0.9910\n",
      "Epoch 47/50\n",
      "33600/33600 [==============================] - 83s 2ms/step - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0571 - val_acc: 0.9900\n",
      "Epoch 48/50\n",
      "33600/33600 [==============================] - 88s 3ms/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0620 - val_acc: 0.9905\n",
      "Epoch 49/50\n",
      "33600/33600 [==============================] - 87s 3ms/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.0626 - val_acc: 0.9899\n",
      "Epoch 50/50\n",
      "33600/33600 [==============================] - 83s 2ms/step - loss: 0.0063 - acc: 0.9985 - val_loss: 0.0475 - val_acc: 0.9895\n"
     ]
    }
   ],
   "source": [
    "# 编译模型\n",
    "cnn_net.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# 运行/训练模型\n",
    "cnn_net.fit(x_train,y_train,batch_size=batch_size,epochs=50,verbose=1,validation_split=0.2)\n",
    "\n",
    "# 保存模型\n",
    "cnn_net.save('save_model/cnn_net_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用保存好的模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 24s 841us/step\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('input/test.csv')\n",
    "\n",
    "x_valid=df.values.astype('float32')\n",
    "\n",
    "n_valid=x_valid.shape[0]\n",
    "\n",
    "x_valid=x_valid.reshape(n_valid,28,28,1)\n",
    "\n",
    "x_valid=x_valid/255.0\n",
    "\n",
    "yPred=cnn_net.predict_classes(x_valid,batch_size=32,verbose=1)\n",
    "\n",
    "np.savetxt('Digit3.csv',np.c_[range(1,len(yPred)+1),yPred],delimiter=',',header='ImageId,Label',comments='',fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
