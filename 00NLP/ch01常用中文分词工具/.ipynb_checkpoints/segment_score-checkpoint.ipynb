{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import jieba\n",
    "import hanlp\n",
    "import pkuseg\n",
    "import thulac\n",
    "from snownlp import SnowNLP\n",
    "import pynlpir\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def mk_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def cal_score(script_score, gold_training_file, gold_test_file, segment_file, out_file):\n",
    "    command_folder_list = ['perl', script_score, gold_training_file, gold_test_file, segment_file,'>', out_file ]\n",
    "    command = ' '.join(command_folder_list)\n",
    "    print(command)\n",
    "    os.system(command)\n",
    "\n",
    "\n",
    "class Segment:\n",
    "    def jieba_segment(self, sentence):\n",
    "        seg_list = jieba.cut(sentence, cut_all=False)\n",
    "        sentence = ' '.join(seg_list)\n",
    "        return sentence\n",
    "\n",
    "    def hanlp_segment(self, han_tokenizer, sentence):\n",
    "        # hanlp分词\n",
    "        sentence = han_tokenizer(sentence)\n",
    "        return ' '.join(sentence)\n",
    "\n",
    "    def thulac_segment(self, thu, sentence):\n",
    "        # thulac 分词\n",
    "        sentence = thu.cut(sentence, text=True)  # 进行一句话分词\n",
    "        # cut_f(输入文件, 输出文件)\n",
    "        return ' '.join(sentence)\n",
    "\n",
    "    def pkuseg_segment(self, sentence):\n",
    "        seg = pkuseg.pkuseg(postag=False)  # 以默认配置加载模型\n",
    "        sentence = seg.cut(sentence)  # 进行分词\n",
    "        return ' '.join(sentence)\n",
    "\n",
    "    def pynlpir_segment(self, sentence):\n",
    "        # pynlpir分词\n",
    "        pynlpir.open()\n",
    "        sentence = pynlpir.segment(sentence, pos_tagging=False)\n",
    "        pynlpir.close()\n",
    "        return ' '.join(sentence)\n",
    "\n",
    "    def snownlp_segment(self, sentence):\n",
    "        # snownlp分词\n",
    "        # unicode_sentence = sentence.decode('gbk')\n",
    "        sentence = SnowNLP(sentence).words\n",
    "        return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jieba\n",
      "pku\n"
     ]
    }
   ],
   "source": [
    "segment_list = ['hanlp', 'jieba', 'snownlp', 'pynlpir', 'pkuseg', 'thulac']\n",
    "data_list = ['cityu', 'as', 'msr', 'pku']\n",
    "#   data = dict(zip(data_list, data_list))\n",
    "segment_tool = 'jieba' # 原作者的思路：挨个输入这些名字，然后测试：这些名字是否在统计列表中\n",
    "data = 'pku'\n",
    "\n",
    "print(segment_tool)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data not in data_list or segment_tool not in segment_list:\n",
    "    print('ERROR the parameters')\n",
    "    print(\"python argv[1]->[hanlp,jieba,snownlp,nlpir,pkuseg,thulac] argv[2]->[cityu, as, msr, pku]\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'data/icwb2/testing/' + data + '_test.utf8'\n",
    "seg_dir = 'data/icwb2/segment/' + segment_tool + '/' \n",
    "seg_path = seg_dir + data + '_segment_test.utf8'\n",
    "gold_training_file = 'data/icwb2/gold/' + data + '_training_words.utf8'\n",
    "gold_test_file = 'data/icwb2/gold/' + data + '_test_gold.utf8'\n",
    "script_score = 'data/icwb2/scripts/score'\n",
    "score_path = 'data/score/' + segment_tool + '/'\n",
    "score_file = score_path + data + '_score'\n",
    "time_statistic_dir = 'data/time_statistic/'\n",
    "time_statistic_path = time_statistic_dir + segment_tool + '_time_statistic.txt'\n",
    "\n",
    "mk_dir(seg_dir)\n",
    "mk_dir(time_statistic_dir)\n",
    "mk_dir(score_path)\n",
    "\n",
    "# eval('test_path' + sys.argv[2])字符串转变量\n",
    "# eval('seg_path' + sys.argv[2])\n",
    "\n",
    "print('test_path=', test_path)\n",
    "print('segment_path=', seg_path)\n",
    "\n",
    "if segment_tool == 'jieba':\n",
    "    jieba.enable_paddle()  # 启动paddle模式。 0.40版之后开始支持，早期版本不支持\n",
    "\n",
    "segment_func = segment_tool + '_segment'\n",
    "start = time.perf_counter()\n",
    "\n",
    "if 'thulac' in segment_func:\n",
    "    thu = thulac.thulac(seg_only=True)\n",
    "if 'hanlp' in segment_func:\n",
    "    han_tokenizer = hanlp.load('PKU_NAME_MERGED_SIX_MONTHS_CONVSEG')\n",
    "with open(test_path, 'r', encoding='utf-8-sig') as f_r:  ##注意，这里的编码，utf-8 bom会在文件头加\\ufeff，否则会有小问题\n",
    "    with open(seg_path, 'w', encoding='utf-8') as f_w:\n",
    "        for line_sentence in f_r:\n",
    "            if 'thulac' in segment_func:\n",
    "                line_sentence = getattr(Segment(), segment_func)(thu, line_sentence)  # 根据参数调用不同分词工具\n",
    "            elif 'hanlp' in segment_func:\n",
    "                line_sentence = getattr(Segment(), segment_func)(han_tokenizer, line_sentence)\n",
    "            else:\n",
    "                line_sentence = getattr(Segment(), segment_func)(line_sentence)  # 根据参数调用不同分词工具\n",
    "            if 'snow' in segment_func:\n",
    "                f_w.write(line_sentence + '\\n')\n",
    "            else:\n",
    "                f_w.write(line_sentence)\n",
    "end = time.perf_counter()\n",
    "\n",
    "with open(time_statistic_path, 'a', encoding='utf-8') as f_time:\n",
    "    print('分词运行时间：', end - start)\n",
    "    dic = {}\n",
    "    dic[test_path[11:-10]] = end - start\n",
    "    f_time.write(json.dumps(dic) + '\\n')\n",
    "\n",
    "print('start scoring','------'*3)\n",
    "#to calculate score\n",
    "cal_score(script_score,gold_training_file, gold_test_file, seg_path, score_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
