{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "copyright-notice"
   },
   "source": [
    "#### Copyright 2017 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "copyright-notice2"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPa95uXvcpcn"
   },
   "source": [
    " # 使用神经网络对手写数字进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fdpn8b90u8Tp"
   },
   "source": [
    " ![img](https://www.tensorflow.org/versions/r0.11/images/MNIST.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7HLCm66Cs2p"
   },
   "source": [
    " **学习目标：**\n",
    "  * 训练线性模型和神经网络，以对传统 [MNIST](http://yann.lecun.com/exdb/mnist/) 数据集中的手写数字进行分类\n",
    "  * 比较线性分类模型和神经网络分类模型的效果\n",
    "  * 可视化神经网络隐藏层的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSEh-gNdu8T0"
   },
   "source": [
    " 我们的目标是将每个输入图片与正确的数字相对应。我们会创建一个包含几个隐藏层的神经网络，并在顶部放置一个归一化指数层，以选出最合适的类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NMdE1b-7UIH"
   },
   "source": [
    " ## 设置\n",
    "\n",
    "首先，我们下载数据集、导入 TensorFlow 和其他实用工具，并将数据加载到 *Pandas* `DataFrame`。请注意，此数据是原始 MNIST 训练数据的样本；我们随机选择了 20000 行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NCOE9iugu8T3"
   },
   "source": [
    "!wget https://storage.googleapis.com/mledu-datasets/mnist_train_small.csv -O /tmp/mnist_train_small.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "4LJ4SD8BWHeh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9   ...   775  776  777  \\\n",
       "6312    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "6404    1    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "5266    0    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "2193    9    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "7082    8    0    0    0    0    0    0    0    0    0 ...     0    0    0   \n",
       "\n",
       "      778  779  780  781  782  783  784  \n",
       "6312    0    0    0    0    0    0    0  \n",
       "6404    0    0    0    0    0    0    0  \n",
       "5266    0    0    0    0    0    0    0  \n",
       "2193    0    0    0    0    0    0    0  \n",
       "7082    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import io\n",
    "import math\n",
    "import os\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format\n",
    "\n",
    "mnist_dataframe = pd.read_csv(\n",
    "  io.open(\"mnist_train_small.csv\", \"r\"),\n",
    "  sep=\",\",\n",
    "  header=None)\n",
    "\n",
    "# Use just the first 10,000 records for training/validation\n",
    "mnist_dataframe = mnist_dataframe.head(10000)\n",
    "\n",
    "mnist_dataframe = mnist_dataframe.reindex(np.random.permutation(mnist_dataframe.index))\n",
    "mnist_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kg0-25p2mOi0"
   },
   "source": [
    " 第一列中包含类别标签。其余列中包含特征值，每个像素对应一个特征值，有 `28×28=784` 个像素值，其中大部分像素值都为零；您也许需要花一分钟时间来确认它们不*全部*为零。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PQ7vuOwRCsZ1"
   },
   "source": [
    " ![img](https://www.tensorflow.org/versions/r0.11/images/MNIST-Matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dghlqJPIu8UM"
   },
   "source": [
    " 这些样本都是分辨率相对较低、对比度相对较高的手写数字图片。`0-9` 这十个数字中的每个可能出现的数字均由唯一的类别标签表示。因此，这是一个具有 10 个类别的多类别分类问题。\n",
    "\n",
    "现在，我们解析一下标签和特征，并查看几个样本。注意 `loc` 的使用，借助 `loc`，我们能够基于原来的位置抽出各列，因为此数据集中没有标题行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "JfFWWvMWDFrR"
   },
   "outputs": [],
   "source": [
    "def parse_labels_and_features(dataset):\n",
    "  \"\"\"Extracts labels and features.\n",
    "  \n",
    "  This is a good place to scale or transform the features if needed.\n",
    "  \n",
    "  Args:\n",
    "    dataset: A Pandas `Dataframe`, containing the label on the first column and\n",
    "      monochrome pixel values on the remaining columns, in row major order.\n",
    "  Returns:\n",
    "    A `tuple` `(labels, features)`:\n",
    "      labels: A Pandas `Series`.\n",
    "      features: A Pandas `DataFrame`.\n",
    "  \"\"\"\n",
    "  labels = dataset[0]\n",
    "\n",
    "  # DataFrame.loc index ranges are inclusive at both ends.\n",
    "  features = dataset.loc[:,1:784]\n",
    "  # Scale the data to [0, 1] by dividing out the max value, 255.\n",
    "  features = features / 255\n",
    "\n",
    "  return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mFY_-7vZu8UU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3      4      5      6      7      8      9      10   \\\n",
       "count 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
       "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       ...      775    776    777    778    779    780    781    782    783  \\\n",
       "count  ...   7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0 7500.0   \n",
       "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "max    ...      1.0    1.0    0.8    0.2    1.0    0.2    0.0    0.0    0.0   \n",
       "\n",
       "         784  \n",
       "count 7500.0  \n",
       "mean     0.0  \n",
       "std      0.0  \n",
       "min      0.0  \n",
       "25%      0.0  \n",
       "50%      0.0  \n",
       "75%      0.0  \n",
       "max      0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_targets, training_examples = parse_labels_and_features(mnist_dataframe[:7500])\n",
    "training_examples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4-Vgg-1zu8Ud"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3      4      5      6      7      8      9      10   \\\n",
       "count 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
       "mean     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "std      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "min      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "25%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "50%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "75%      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "max      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "       ...      775    776    777    778    779    780    781    782    783  \\\n",
       "count  ...   2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0 2500.0   \n",
       "mean   ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "std    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "min    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "25%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "50%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "75%    ...      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "max    ...      0.3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         784  \n",
       "count 2500.0  \n",
       "mean     0.0  \n",
       "std      0.0  \n",
       "min      0.0  \n",
       "25%      0.0  \n",
       "50%      0.0  \n",
       "75%      0.0  \n",
       "max      0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_targets, validation_examples = parse_labels_and_features(mnist_dataframe[7500:10000])\n",
    "validation_examples.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wrnAI1v6u8Uh"
   },
   "source": [
    " 显示一个随机样本及其对应的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s-euVJVtu8Ui"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEGCAYAAACq4kOvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223d32eecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_example = np.random.choice(training_examples.index)\n",
    "_, ax = plt.subplots()\n",
    "ax.matshow(training_examples.loc[rand_example].values.reshape(28, 28))\n",
    "ax.set_title(\"Label: %i\" % training_targets.loc[rand_example])\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ScmYX7xdZMXE"
   },
   "source": [
    " ## 任务 1：为 MNIST 构建线性模型\n",
    "\n",
    "首先，我们创建一个基准模型，作为比较对象。`LinearClassifier` 可提供一组 *k* 类一对多分类器，每个类别（共 *k* 个）对应一个分类器。\n",
    "\n",
    "您会发现，除了报告准确率和绘制对数损失函数随时间变化情况的曲线图之外，我们还展示了一个[**混淆矩阵**](https://en.wikipedia.org/wiki/Confusion_matrix)。混淆矩阵会显示错误分类为其他类别的类别。哪些数字相互之间容易混淆？\n",
    "\n",
    "另请注意，我们会使用 `log_loss` 函数跟踪模型的错误。不应将此函数与用于训练的 `LinearClassifier` 内部损失函数相混淆。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "cpoVC4TSdw5Z"
   },
   "outputs": [],
   "source": [
    "def construct_feature_columns():\n",
    "  \"\"\"Construct the TensorFlow Feature Columns.\n",
    "\n",
    "  Returns:\n",
    "    A set of feature columns\n",
    "  \"\"\" \n",
    "  \n",
    "  # There are 784 pixels in each image \n",
    "  return set([tf.feature_column.numeric_column('pixels', shape=784)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kMmL89yGeTfz"
   },
   "source": [
    " 在本次练习中，我们会对训练和预测使用单独的输入函数，并将这些函数分别嵌套在 `create_training_input_fn()` 和 `create_predict_input_fn()` 中，这样一来，我们就可以调用这些函数，以返回相应的 `_input_fn`，并将其传递到 `.train()` 和 `.predict()` 调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OeS47Bmn5Ms2"
   },
   "outputs": [],
   "source": [
    "def create_training_input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
    "  \"\"\"A custom input_fn for sending MNIST data to the estimator for training.\n",
    "\n",
    "  Args:\n",
    "    features: The training features.\n",
    "    labels: The training labels.\n",
    "    batch_size: Batch size to use during training.\n",
    "\n",
    "  Returns:\n",
    "    A function that returns batches of training features and labels during\n",
    "    training.\n",
    "  \"\"\"\n",
    "  def _input_fn(num_epochs=None, shuffle=True):\n",
    "    # Input pipelines are reset with each call to .train(). To ensure model\n",
    "    # gets a good sampling of data, even when steps is small, we \n",
    "    # shuffle all the data before creating the Dataset object\n",
    "    idx = np.random.permutation(features.index)\n",
    "    raw_features = {\"pixels\":features.reindex(idx)}\n",
    "    raw_targets = np.array(labels[idx])\n",
    "   \n",
    "    ds = Dataset.from_tensor_slices((raw_features,raw_targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data\n",
    "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "    return feature_batch, label_batch\n",
    "\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8zoGWAoohrwS"
   },
   "outputs": [],
   "source": [
    "def create_predict_input_fn(features, labels, batch_size):\n",
    "  \"\"\"A custom input_fn for sending mnist data to the estimator for predictions.\n",
    "\n",
    "  Args:\n",
    "    features: The features to base predictions on.\n",
    "    labels: The labels of the prediction examples.\n",
    "\n",
    "  Returns:\n",
    "    A function that returns features and labels for predictions.\n",
    "  \"\"\"\n",
    "  def _input_fn():\n",
    "    raw_features = {\"pixels\": features.values}\n",
    "    raw_targets = np.array(labels)\n",
    "    \n",
    "    ds = Dataset.from_tensor_slices((raw_features, raw_targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size)\n",
    "    \n",
    "        \n",
    "    # Return the next batch of data\n",
    "    feature_batch, label_batch = ds.make_one_shot_iterator().get_next()\n",
    "    return feature_batch, label_batch\n",
    "\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "G6DjSLZMu8Um"
   },
   "outputs": [],
   "source": [
    "def train_linear_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a linear classification model for the MNIST digits dataset.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  a plot of the training and validation loss over time, and a confusion\n",
    "  matrix.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: An `int`, the learning rate to use.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    training_examples: A `DataFrame` containing the training features.\n",
    "    training_targets: A `DataFrame` containing the training labels.\n",
    "    validation_examples: A `DataFrame` containing the validation features.\n",
    "    validation_targets: A `DataFrame` containing the validation labels.\n",
    "      \n",
    "  Returns:\n",
    "    The trained `LinearClassifier` object.\n",
    "  \"\"\"\n",
    "\n",
    "  periods = 10\n",
    "\n",
    "  steps_per_period = steps / periods  \n",
    "  # Create the input functions.\n",
    "  predict_training_input_fn = create_predict_input_fn(\n",
    "    training_examples, training_targets, batch_size)\n",
    "  predict_validation_input_fn = create_predict_input_fn(\n",
    "    validation_examples, validation_targets, batch_size)\n",
    "  training_input_fn = create_training_input_fn(\n",
    "    training_examples, training_targets, batch_size)\n",
    "  \n",
    "  # Create a LinearClassifier object.\n",
    "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  classifier = tf.estimator.LinearClassifier(\n",
    "      feature_columns=construct_feature_columns(),\n",
    "      n_classes=10,\n",
    "      optimizer=my_optimizer,\n",
    "      config=tf.estimator.RunConfig(keep_checkpoint_max=1)\n",
    "  )\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print (\"Training model...\")\n",
    "  print (\"LogLoss error (on validation data):\")\n",
    "  training_errors = []\n",
    "  validation_errors = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    classifier.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "  \n",
    "    # Take a break and compute probabilities.\n",
    "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
    "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
    "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
    "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
    "        \n",
    "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
    "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
    "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
    "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
    "    \n",
    "    # Compute training and validation errors.\n",
    "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
    "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
    "    # Occasionally print the current loss.\n",
    "    print (\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_errors.append(training_log_loss)\n",
    "    validation_errors.append(validation_log_loss)\n",
    "  print (\"Model training finished.\")\n",
    "  # Remove event files to save disk space.\n",
    "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
    "  \n",
    "  # Calculate final predictions (not probabilities, as above).\n",
    "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
    "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
    "  \n",
    "  \n",
    "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
    "  print (\"Final accuracy (on validation data): %0.2f\" % accuracy  )\n",
    "\n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"LogLoss\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"LogLoss vs. Periods\")\n",
    "  plt.plot(training_errors, label=\"training\")\n",
    "  plt.plot(validation_errors, label=\"validation\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  \n",
    "  # Output a plot of the confusion matrix.\n",
    "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
    "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
    "  # in each class)\n",
    "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "  ax.set_aspect(1)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.ylabel(\"True label\")\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "  plt.show()\n",
    "\n",
    "  return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItHIUyv2u8Ur"
   },
   "source": [
    " **花费 5 分钟的时间了解一下使用这种形式的线性模型时，准确率方面表现如何。在本次练习中，为自己设定限制，仅使用批量大小、学习速率和步数这三个超参数进行试验。**\n",
    "\n",
    "如果您从上述任何试验中得到的准确率约为 0.9，即可停止试验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yaiIhIQqu8Uv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "LogLoss error (on validation data):\n",
      "  period 00 : 17.31\n",
      "  period 01 : 11.90\n",
      "  period 02 : 9.92\n",
      "  period 03 : 9.80\n",
      "  period 04 : 7.45\n",
      "  period 05 : 6.67\n",
      "  period 06 : 7.89\n",
      "  period 07 : 7.03\n",
      "  period 08 : 6.22\n",
      "  period 09 : 6.36\n",
      "Model training finished.\n",
      "Final accuracy (on validation data): 0.82\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/Nz/A6mtGwX/fBfbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22382dc0c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAEWCAYAAAAdG+ASAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22383cbf128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = train_linear_classification_model(\n",
    "             learning_rate=0.02,\n",
    "             steps=100,\n",
    "             batch_size=10,\n",
    "             training_examples=training_examples,\n",
    "             training_targets=training_targets,\n",
    "             validation_examples=validation_examples,\n",
    "             validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "266KQvZoMxMv"
   },
   "source": [
    " ### 解决方案\n",
    "\n",
    "点击下方即可查看一种可能的解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRWcn24DM3qa"
   },
   "source": [
    " 以下是一组使准确率应该约为 0.9 的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TGlBMrUoM1K_"
   },
   "outputs": [],
   "source": [
    "_ = train_linear_classification_model(\n",
    "    learning_rate=0.03,\n",
    "    steps=1000,\n",
    "    batch_size=30,\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mk095OfpPdOx"
   },
   "source": [
    " ## 任务 2：使用神经网络替换线性分类器\n",
    "\n",
    "**使用 [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier) 替换上面的 LinearClassifier，并查找可实现 0.95 或更高准确率的参数组合。**\n",
    "\n",
    "您可能希望尝试 Dropout 等其他正则化方法。这些额外的正则化方法已记录在 `DNNClassifier` 类的注释中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rm8P_Ttwu8U4"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE: Replace the linear classifier with a neural network.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOfmiSvqu8U9"
   },
   "source": [
    " 获得出色的模型后，通过评估我们将在下面加载的测试数据进行仔细检查，确认您没有过拟合验证集。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rZsMYFo7u8VB"
   },
   "source": [
    "!wget https://storage.googleapis.com/mledu-datasets/mnist_test.csv -O /tmp/mnist_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "evlB5ubzu8VJ"
   },
   "outputs": [],
   "source": [
    "mnist_test_dataframe = pd.read_csv(\n",
    "  io.open(\"/tmp/mnist_test.csv\", \"r\"),\n",
    "  sep=\",\",\n",
    "  header=None)\n",
    "\n",
    "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
    "test_examples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PDuLd2Hcu8VL"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# YOUR CODE HERE: Calculate accuracy on the test set.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sfw3LH0Oycm"
   },
   "source": [
    " ### 解决方案\n",
    "\n",
    "点击下方即可查看可能的解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XatDGFKEO374"
   },
   "source": [
    " 除了神经网络专用配置（例如隐藏单元的超参数）之外，以下代码与原始的 `LinearClassifer` 训练代码几乎完全相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kdNTx8jkPQUx"
   },
   "outputs": [],
   "source": [
    "def train_nn_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    hidden_units,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "  \"\"\"Trains a neural network classification model for the MNIST digits dataset.\n",
    "  \n",
    "  In addition to training, this function also prints training progress information,\n",
    "  a plot of the training and validation loss over time, as well as a confusion\n",
    "  matrix.\n",
    "  \n",
    "  Args:\n",
    "    learning_rate: An `int`, the learning rate to use.\n",
    "    steps: A non-zero `int`, the total number of training steps. A training step\n",
    "      consists of a forward and backward pass using a single batch.\n",
    "    batch_size: A non-zero `int`, the batch size.\n",
    "    hidden_units: A `list` of int values, specifying the number of neurons in each layer.\n",
    "    training_examples: A `DataFrame` containing the training features.\n",
    "    training_targets: A `DataFrame` containing the training labels.\n",
    "    validation_examples: A `DataFrame` containing the validation features.\n",
    "    validation_targets: A `DataFrame` containing the validation labels.\n",
    "      \n",
    "  Returns:\n",
    "    The trained `DNNClassifier` object.\n",
    "  \"\"\"\n",
    "\n",
    "  periods = 10\n",
    "  # Caution: input pipelines are reset with each call to train. \n",
    "  # If the number of steps is small, your model may never see most of the data.  \n",
    "  # So with multiple `.train` calls like this you may want to control the length \n",
    "  # of training with num_epochs passed to the input_fn. Or, you can do a really-big shuffle, \n",
    "  # or since it's in-memory data, shuffle all the data in the `input_fn`.\n",
    "  steps_per_period = steps / periods  \n",
    "  # Create the input functions.\n",
    "  predict_training_input_fn = create_predict_input_fn(\n",
    "    training_examples, training_targets, batch_size)\n",
    "  predict_validation_input_fn = create_predict_input_fn(\n",
    "    validation_examples, validation_targets, batch_size)\n",
    "  training_input_fn = create_training_input_fn(\n",
    "    training_examples, training_targets, batch_size)\n",
    "  \n",
    "  # Create the input functions.\n",
    "  predict_training_input_fn = create_predict_input_fn(\n",
    "    training_examples, training_targets, batch_size)\n",
    "  predict_validation_input_fn = create_predict_input_fn(\n",
    "    validation_examples, validation_targets, batch_size)\n",
    "  training_input_fn = create_training_input_fn(\n",
    "    training_examples, training_targets, batch_size)\n",
    "  \n",
    "  # Create feature columns.\n",
    "  feature_columns = [tf.feature_column.numeric_column('pixels', shape=784)]\n",
    "\n",
    "  # Create a DNNClassifier object.\n",
    "  my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "  classifier = tf.estimator.DNNClassifier(\n",
    "      feature_columns=feature_columns,\n",
    "      n_classes=10,\n",
    "      hidden_units=hidden_units,\n",
    "      optimizer=my_optimizer,\n",
    "      config=tf.contrib.learn.RunConfig(keep_checkpoint_max=1)\n",
    "  )\n",
    "\n",
    "  # Train the model, but do so inside a loop so that we can periodically assess\n",
    "  # loss metrics.\n",
    "  print (\"Training model...\")\n",
    "  print (\"LogLoss error (on validation data):\")\n",
    "  training_errors = []\n",
    "  validation_errors = []\n",
    "  for period in range (0, periods):\n",
    "    # Train the model, starting from the prior state.\n",
    "    classifier.train(\n",
    "        input_fn=training_input_fn,\n",
    "        steps=steps_per_period\n",
    "    )\n",
    "  \n",
    "    # Take a break and compute probabilities.\n",
    "    training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
    "    training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
    "    training_pred_class_id = np.array([item['class_ids'][0] for item in training_predictions])\n",
    "    training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,10)\n",
    "        \n",
    "    validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
    "    validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
    "    validation_pred_class_id = np.array([item['class_ids'][0] for item in validation_predictions])\n",
    "    validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,10)    \n",
    "    \n",
    "    # Compute training and validation errors.\n",
    "    training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
    "    validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
    "    # Occasionally print the current loss.\n",
    "    print (\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
    "    # Add the loss metrics from this period to our list.\n",
    "    training_errors.append(training_log_loss)\n",
    "    validation_errors.append(validation_log_loss)\n",
    "  print (\"Model training finished.\")\n",
    "  # Remove event files to save disk space.\n",
    "  _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
    "  \n",
    "  # Calculate final predictions (not probabilities, as above).\n",
    "  final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
    "  final_predictions = np.array([item['class_ids'][0] for item in final_predictions])\n",
    "  \n",
    "  \n",
    "  accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
    "  print (\"Final accuracy (on validation data): %0.2f\" % accuracy ) \n",
    "\n",
    "  # Output a graph of loss metrics over periods.\n",
    "  plt.ylabel(\"LogLoss\")\n",
    "  plt.xlabel(\"Periods\")\n",
    "  plt.title(\"LogLoss vs. Periods\")\n",
    "  plt.plot(training_errors, label=\"training\")\n",
    "  plt.plot(validation_errors, label=\"validation\")\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  \n",
    "  # Output a plot of the confusion matrix.\n",
    "  cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
    "  # Normalize the confusion matrix by row (i.e by the number of samples\n",
    "  # in each class)\n",
    "  cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "  ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "  ax.set_aspect(1)\n",
    "  plt.title(\"Confusion matrix\")\n",
    "  plt.ylabel(\"True label\")\n",
    "  plt.xlabel(\"Predicted label\")\n",
    "  plt.show()\n",
    "\n",
    "  return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZfzsTYGPPU8I"
   },
   "outputs": [],
   "source": [
    "classifier = train_nn_classification_model(\n",
    "    learning_rate=0.05,\n",
    "    steps=1000,\n",
    "    batch_size=30,\n",
    "    hidden_units=[100, 100],\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXvrOgtUR-zD"
   },
   "source": [
    " 接下来，我们来验证测试集的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iDXpZ0jwSCaL"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/mledu-datasets/mnist_test.csv -O /tmp/mnist_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "scQNpDePSFjt"
   },
   "outputs": [],
   "source": [
    "mnist_test_dataframe = pd.read_csv(\n",
    "  io.open(\"mnist_test.csv\", \"r\"),\n",
    "  sep=\",\",\n",
    "  header=None)\n",
    "\n",
    "test_targets, test_examples = parse_labels_and_features(mnist_test_dataframe)\n",
    "test_examples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EVaWpWKvSHmu"
   },
   "outputs": [],
   "source": [
    "predict_test_input_fn = create_predict_input_fn(\n",
    "    test_examples, test_targets, batch_size=100)\n",
    "\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['class_ids'][0] for item in test_predictions])\n",
    "  \n",
    "accuracy = metrics.accuracy_score(test_targets, test_predictions)\n",
    "print (\"Accuracy on test data: %0.2f\" % accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WX2mQBAEcisO"
   },
   "source": [
    " ## 任务 3：可视化第一个隐藏层的权重。\n",
    "\n",
    "我们来花几分钟时间看看模型的 `weights_` 属性，以深入探索我们的神经网络，并了解它学到了哪些规律。\n",
    "\n",
    "模型的输入层有 `784` 个权重，对应于 `28×28` 像素输入图片。第一个隐藏层将有 `784×N` 个权重，其中 `N` 指的是该层中的节点数。我们可以将这些权重重新变回 `28×28` 像素的图片，具体方法是将 `N` 个 `1×784` 权重数组*变形*为 `N` 个 `28×28` 大小数组。\n",
    "\n",
    "运行以下单元格，绘制权重曲线图。请注意，此单元格要求名为 \"classifier\" 的 `DNNClassifier` 已经过训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "eUC0Z8nbafgG"
   },
   "outputs": [],
   "source": [
    "print classifier.get_variable_names()\n",
    "\n",
    "weights0 = classifier.get_variable_value(\"dnn/hiddenlayer_0/kernel\")\n",
    "\n",
    "print \"weights0 shape:\", weights0.shape\n",
    "\n",
    "num_nodes = weights0.shape[1]\n",
    "num_rows = int(math.ceil(num_nodes / 10.0))\n",
    "fig, axes = plt.subplots(num_rows, 10, figsize=(20, 2 * num_rows))\n",
    "for coef, ax in zip(weights0.T, axes.ravel()):\n",
    "    # Weights in coef is reshaped from 1x784 to 28x28.\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.pink)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kL8MEhNgrx9N"
   },
   "source": [
    " 神经网络的第一个隐藏层应该会对一些级别特别低的特征进行建模，因此可视化权重可能只显示一些模糊的区域，也可能只显示数字的某几个部分。此外，您可能还会看到一些基本上是噪点（这些噪点要么不收敛，要么被更高的层忽略）的神经元。\n",
    "\n",
    "在迭代不同的次数后停止训练并查看效果，可能会发现有趣的结果。\n",
    "\n",
    "**分别用 10、100 和 1000 步训练分类器。然后重新运行此可视化。**\n",
    "\n",
    "您看到不同级别的收敛之间有哪些直观上的差异？"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "266KQvZoMxMv",
    "6sfw3LH0Oycm",
    "copyright-notice"
   ],
   "default_view": {},
   "name": "multi-class_classification_of_handwritten_digits.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
