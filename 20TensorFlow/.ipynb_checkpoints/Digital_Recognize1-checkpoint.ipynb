{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 入门\n",
    "\n",
    "参考：\n",
    "\n",
    "https://mp.weixin.qq.com/s?__biz=MzI2OTc5NTUwNg==&mid=2247484530&idx=2&sn=158434d20b8e8796a3dbcece6e603d4c&chksm=eadbadafddac24b91e9cb249340f120721181d5a1b952570c079ed09059ce0291ef7daef9fcd&scene=21#wechat_redirect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**基本概念：**\n",
    "\n",
    "1、 图（Graph）：用来表示计算任务，也就我们要做的一些操作。\n",
    "\n",
    "2 、会话（Session）：建立会话，此时会生成一张空图；在会话中添加节点和边，形成一张图，一个会话可以有多个图，通过执行这些图得到结果。如果把每个图看做一个车床，那会话就是一个车间，里面有若干个车床，用来把数据生产成结果。\n",
    "\n",
    "3 、Tensor：用来表示数据，是我们的原料。\n",
    "\n",
    "4、 变量（Variable）：用来记录一些数据和状态，是我们的容器。\n",
    "\n",
    "5、 feed和fetch：可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据。相当于一些铲子，可以操作数据。\n",
    "\n",
    "形象的比喻是：把会话看做车间，图看做车床，里面用Tensor做原料，变量做容器，feed和fetch做铲子，把数据加工成我们的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入包**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建图和运行图（常量的创建与计算）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建常量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个常量\n",
    "con1=tf.constant([[2,3]])\n",
    "\n",
    "# 创建另一个常量\n",
    "con2=tf.constant([[2],[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建矩阵乘法节点**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "product=tf.matmul(con1,con2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义&运行会话**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13]]\n"
     ]
    }
   ],
   "source": [
    "# 定义会话\n",
    "sess=tf.Session()\n",
    "\n",
    "# 执行会话得到结果\n",
    "result=sess.run(product)\n",
    "\n",
    "# 打印结果\n",
    "print(result)\n",
    "\n",
    "# 关闭会话\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建变量并赋值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建变量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个变量，初始值为0，名字是count\n",
    "num=tf.Variable(0,name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建加法操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加法操作，每次加10\n",
    "new_value=tf.add(num,10)\n",
    "\n",
    "# 赋值操作，把加过的值赋值给num\n",
    "op=tf.assign(num,new_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**开启会话，并让它自动关闭**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # 变量一定记得初始化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 打印变量初始值\n",
    "    print(sess.run(num))\n",
    "    \n",
    "    # 循环赋值\n",
    "    for i in range(0,5):\n",
    "        sess.run(op)\n",
    "        print(sess.run(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们发现，我们不用自己去操作累加的那一步（sess.run(new_value)),只需要在session中执行最后的赋值就可以了（sess.run(new_value)）。\n",
    "\n",
    "是因为在tensorflow的设计中，它会自动去寻找执行的节点所依赖的节点，并去执行前置的依赖节点。\n",
    "\n",
    "唔，这个就和依赖注入有点像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 声明变量\n",
    "\n",
    "之前我们在声明变量的同时赋了初始值，但有的时候，如果我们不想赋初始值呢？\n",
    "\n",
    "这个时候，就要用占位符（placeholder）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建占位符**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为变量1创建一个占位符\n",
    "input1=tf.placeholder(tf.float32)\n",
    "\n",
    "# 为变量2创建一个占位符\n",
    "input2=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为这两个变量写好操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两个变量执行加法操作\n",
    "new_value=tf.add(input1,input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**开启会话**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    # 创建给占位符输入的内容\n",
    "    feed_dict={input1:32.1,input2:23.2}\n",
    "    \n",
    "    # 执行节点\n",
    "    result=sess.run(new_value,feed_dict=feed_dict)\n",
    "    \n",
    "    # 打印结果\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "\n",
    "接下来就要用tensorflow搭建一个简单的深度学习模型来进行手写字母的识别了。\n",
    "\n",
    "首先导入数据处理包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读入数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('input/train.csv',index_col=False)\n",
    "test_raw_data=pd.read_csv('input/test.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分割label和训练集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=train_raw_data.iloc[:,1:].values\n",
    "labels_flat=train_raw_data.iloc[:,0].values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对训练样本做预处理\n",
    "\n",
    "这里简单做个处理：\n",
    "\n",
    "    1、归一化，0~255的范围太大，我们把它缩小到0~1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**归一化处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=images.astype(np.float)\n",
    "images=np.multiply(images,1.0 / 255.0)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_size=images.shape[1]\n",
    "image_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对训练label做处理\n",
    "\n",
    "简单想一下，我们这个其实是一个分类问题，对于每个数字而言，都可以看做是一个one-vs-all的问题。\n",
    "\n",
    "因此，我们的网络最终输出的是一个10*1的向量，只有一个位置是1，其他位置是0.\n",
    "\n",
    "因此，需要对train_y做一个one_hot编码。\n",
    "\n",
    "下面介绍两种one-hot的方式，一种是自己写代码，一种是利用pandas的函数。\n",
    "\n",
    "自己写代码，不用通过pandas，这样内存压力小一点；pandas写得效率高一些。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**利用自己写得代码进行one-hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_count=np.unique(labels_flat).shape[0]\n",
    "labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dense_to_one_hot(labels_dense,num_classes):\n",
    "    num_labels=labels_dense.shape[0]\n",
    "    # 计算每一行所需要的偏移量\n",
    "    index_offset=np.arange(num_labels)*num_classes\n",
    "    labels_one_hot=np.zeros((num_labels,num_classes))\n",
    "    # 把一个n*n的矩阵看做是一个1*n²的行向量，进行赋值\n",
    "    labels_one_hot.flat[index_offset+labels_dense.ravel()]=1\n",
    "    # 得到one-hot\n",
    "    return labels_one_hot\n",
    "\n",
    "labels=dense_to_one_hot(labels_flat,labels_count)\n",
    "labels=labels.astype(np.uint8)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**利用pandas进行one-hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 重新拿到数据\n",
    "# train_y_one_hot=images.iloc[:,0]\n",
    "\n",
    "# # 进行one-hot\n",
    "# train_y_one_hot_real=pd.get_dummies(train_y_one_hot,prefix='Num:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 从dataframe转化成numpy形式\n",
    "# result_one_hot=train_y_one_hot_real.values\n",
    "# # 输出\n",
    "# result_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集划分\n",
    "\n",
    "神经网络需要调整许多的超参数，因此我们需要把训练集再分割，分成训练集和验证集两部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE=2000\n",
    "\n",
    "validation_images=train_x_nor[:VALIDATION_SIZE]\n",
    "validation_labels=result_one_hot[:VALIDATION_SIZE]\n",
    "\n",
    "train_images=train_x_nor[VALIDATION_SIZE:]\n",
    "train_labels=result_one_hot[VALIDATION_SIZE:]\n",
    "\n",
    "# train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机梯度下降\n",
    "\n",
    "呃，一次使用所有的数据行进行训练慢，而且内存吃不消，因此采用随机梯度下降，即批量梯度下降的方式来进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "n_batch=int(len(train_images)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建神经网络模型\n",
    "\n",
    "我们的神经网络的超参数：\n",
    "\n",
    "    1. 激活函数：softmax\n",
    "    2. 损失函数：交叉熵\n",
    "    3. 优化方式：梯度下降\n",
    "    4. 输入层：784个节点，对应每个像素点。\n",
    "    5. 隐层：只有一个隐层，10个节点，同时作为输出层。\n",
    "    6. 输出层：就是隐层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**训练数据的占位符**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=train_images.shape[1]\n",
    "x=tf.placeholder(tf.float32,shape=[None,image_size])\n",
    "x2=tf.placeholder(tf.float32,shape=[None,image_size])\n",
    "y = tf.placeholder(tf.float32, shape=[None, labels_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**中间参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个weights表示第一隐层只有10个节点\n",
    "weights=tf.Variable(tf.zeros([784,10]))\n",
    "\n",
    "# biases,偏差，相当于y=ax+b中的b\n",
    "biases=tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# result,定义第一隐层的输出\n",
    "result=tf.matmul(x,weights)+biases\n",
    "\n",
    "# prediction，激活函数，对线性计算结果添加非线性内容。\n",
    "prediction=tf.nn.softmax(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创建损失函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**用梯度下降来进行优化**\n",
    "\n",
    "学习率为0.1，最小化loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step=tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**初始化变量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**计算精度**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**开始训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮，准确度为：0.54\n",
      "第2轮，准确度为：0.693\n",
      "第3轮，准确度为：0.771\n",
      "第4轮，准确度为：0.7835\n",
      "第5轮，准确度为：0.793\n",
      "第6轮，准确度为：0.7985\n",
      "第7轮，准确度为：0.803\n",
      "第8轮，准确度为：0.8065\n",
      "第9轮，准确度为：0.8075\n",
      "第10轮，准确度为：0.8075\n",
      "第11轮，准确度为：0.8105\n",
      "第12轮，准确度为：0.8125\n",
      "第13轮，准确度为：0.814\n",
      "第14轮，准确度为：0.8155\n",
      "第15轮，准确度为：0.816\n",
      "第16轮，准确度为：0.8175\n",
      "第17轮，准确度为：0.8175\n",
      "第18轮，准确度为：0.821\n",
      "第19轮，准确度为：0.8335\n",
      "第20轮，准确度为：0.85\n",
      "第21轮，准确度为：0.8585\n",
      "第22轮，准确度为：0.862\n",
      "第23轮，准确度为：0.8685\n",
      "第24轮，准确度为：0.8715\n",
      "第25轮，准确度为：0.8745\n",
      "第26轮，准确度为：0.8795\n",
      "第27轮，准确度为：0.8795\n",
      "第28轮，准确度为：0.881\n",
      "第29轮，准确度为：0.884\n",
      "第30轮，准确度为：0.886\n",
      "第31轮，准确度为：0.8875\n",
      "第32轮，准确度为：0.8885\n",
      "第33轮，准确度为：0.89\n",
      "第34轮，准确度为：0.8905\n",
      "第35轮，准确度为：0.8915\n",
      "第36轮，准确度为：0.891\n",
      "第37轮，准确度为：0.8915\n",
      "第38轮，准确度为：0.8935\n",
      "第39轮，准确度为：0.894\n",
      "第40轮，准确度为：0.894\n",
      "第41轮，准确度为：0.8945\n",
      "第42轮，准确度为：0.895\n",
      "第43轮，准确度为：0.895\n",
      "第44轮，准确度为：0.895\n",
      "第45轮，准确度为：0.8955\n",
      "第46轮，准确度为：0.8965\n",
      "第47轮，准确度为：0.897\n",
      "第48轮，准确度为：0.897\n",
      "第49轮，准确度为：0.898\n",
      "第50轮，准确度为：0.8985\n"
     ]
    }
   ],
   "source": [
    "new_value=tf.add(x,x2)\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(init)\n",
    "    \n",
    "    # 循环50轮\n",
    "    for epoch in range(50):\n",
    "        for batch in range(n_batch):\n",
    "            # 按照batch取出数据\n",
    "            batch_x=train_images[batch*batch_size:(batch+1)*batch_size]\n",
    "            batch_y=train_labels[batch*batch_size:(batch+1)*batch_size]\n",
    "            # 开始训练\n",
    "            sess.run(train_step,feed_dict={x:batch_x,y:batch_y})\n",
    "        # 每一轮训练计算结果\n",
    "        accuracy_n=sess.run(accuracy,feed_dict={x:validation_images,y:validation_labels})\n",
    "        # 打印结果\n",
    "        print(\"第\"+str(epoch+1)+\"轮，准确度为：\"+str(accuracy_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "802px",
    "left": "0px",
    "right": "953.28125px",
    "top": "110px",
    "width": "371px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
