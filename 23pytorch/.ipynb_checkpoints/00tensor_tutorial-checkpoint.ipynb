{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is PyTorch? 什么是PyTorch?\n",
    "================\n",
    "\n",
    "基于Python的科学计算包，针对两种用户：\n",
    "-  用GPUs的力量代替NumPy\n",
    "-  提供最大灵活性和速度的深度学习研究平台\n",
    "\n",
    "入门指南\n",
    "---------------\n",
    "\n",
    "Tensors 张量\n",
    "\n",
    "张量和NumPy的ndarray相似，此外，张量还可以用于GPU加速计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造一个未初始化的5x3矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-04 *\n",
      "       [[ 0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-1.6487,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000],\n",
      "        [-1.6695,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造一个随机初始化的矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4302,  0.4882,  0.7479],\n",
      "        [ 0.6593,  0.5342,  0.4782],\n",
      "        [ 0.9553,  0.8458,  0.8879],\n",
      "        [ 0.5151,  0.2633,  0.6240],\n",
      "        [ 0.8034,  0.4611,  0.9360]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建一个充满0（dtype long 类型）的矩阵："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接从数据中构造一个张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5.5000,  3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在现有张量的基础上建立一个张量。\n",
    "这些方法将重用输入张量的属性，如dtype，除非用户提供新的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]], dtype=torch.float64)\n",
      "tensor([[ 1.4728, -0.0207,  0.7442],\n",
      "        [-1.1181, -0.0440, -0.1143],\n",
      "        [-0.4801, -0.8028, -1.4296],\n",
      "        [ 0.7651,  1.1484,  1.3892],\n",
      "        [ 0.9392,  1.0534, -1.2495]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
    "print(x)                                      # result has the same size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到它的大小:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n",
    "\n",
    "``torch.Size``实际上是一个元组，所以它支持所有的tuple操作。\n",
    "\n",
    "Operations 操作\n",
    "\n",
    "There are multiple syntaxes for operations. In the following example, we will take a look at the addition operation.\n",
    "\n",
    "操作有多个语法。在下面的例子中，我们看一看加法操作的几种语法。\n",
    "\n",
    "Addition: syntax 1\n",
    "\n",
    "加法：语法1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1478,  0.2318,  0.9769],\n",
      "        [-0.6547,  0.9241,  0.6656],\n",
      "        [-0.4033, -0.2479, -0.6643],\n",
      "        [ 1.0087,  1.6271,  1.4563],\n",
      "        [ 0.9689,  2.0410, -0.2961]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: syntax 2\n",
    "\n",
    "加法：语法2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1478,  0.2318,  0.9769],\n",
      "        [-0.6547,  0.9241,  0.6656],\n",
      "        [-0.4033, -0.2479, -0.6643],\n",
      "        [ 1.0087,  1.6271,  1.4563],\n",
      "        [ 0.9689,  2.0410, -0.2961]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: providing an output tensor as argument\n",
    "\n",
    "加法：作为参数提供一个输出张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1478,  0.2318,  0.9769],\n",
      "        [-0.6547,  0.9241,  0.6656],\n",
      "        [-0.4033, -0.2479, -0.6643],\n",
      "        [ 1.0087,  1.6271,  1.4563],\n",
      "        [ 0.9689,  2.0410, -0.2961]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addition: in-place\n",
    "\n",
    "加法：in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4728, -0.0207,  0.7442],\n",
      "        [-1.1181, -0.0440, -0.1143],\n",
      "        [-0.4801, -0.8028, -1.4296],\n",
      "        [ 0.7651,  1.1484,  1.3892],\n",
      "        [ 0.9392,  1.0534, -1.2495]])\n",
      "tensor([[ 2.1478,  0.2318,  0.9769],\n",
      "        [-0.6547,  0.9241,  0.6656],\n",
      "        [-0.4033, -0.2479, -0.6643],\n",
      "        [ 1.0087,  1.6271,  1.4563],\n",
      "        [ 0.9689,  2.0410, -0.2961]])\n"
     ]
    }
   ],
   "source": [
    "# adds x to y\n",
    "y.add_(x)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
    "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n",
    "\n",
    "## 任何对一个张量进行改变的操作都是用\"\\_\"做后缀。\n",
    "\n",
    "例如： ``x.copy_(y)``, ``x.t_()``,将会改变 ``x``.\n",
    "\n",
    "You can use standard NumPy-like indexing with all bells and whistles!\n",
    "\n",
    "您可以使用标准的“NumPy-like索引”这样诱人的功能！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8756,  1.2712,  0.0150,  1.7948])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])# X[:,0]就是取所有行的第0个数据, X[:,1] 就是取所有行的第1个数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整大小：如果你想要调整/重塑张量，你可以使用“torch.view”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4417,  0.8756, -0.9419,  0.8557],\n",
      "        [ 1.0191,  1.2712,  0.9177,  0.4022],\n",
      "        [-0.0385,  0.0150, -0.4862, -0.2996],\n",
      "        [ 1.5960,  1.7948, -1.0182,  1.4542]])\n",
      "tensor([-0.4417,  0.8756, -0.9419,  0.8557,  1.0191,  1.2712,  0.9177,\n",
      "         0.4022, -0.0385,  0.0150, -0.4862, -0.2996,  1.5960,  1.7948,\n",
      "        -1.0182,  1.4542])\n",
      "tensor([[-0.4417,  0.8756, -0.9419,  0.8557,  1.0191,  1.2712,  0.9177,\n",
      "          0.4022],\n",
      "        [-0.0385,  0.0150, -0.4862, -0.2996,  1.5960,  1.7948, -1.0182,\n",
      "          1.4542]])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果你有一个元素张量，使用'.item（）'来取值作为Python的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1962])\n",
      "-1.1962311267852783\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later:**\n",
    "稍后阅读\n",
    "\n",
    "100多个张量运算，包括转置，索引，切片，数学运算，线性代数，随机数等等，在这里描述< http://pytorch.org/docs/torch > _。\n",
    "\n",
    "NumPy Bridge\n",
    "------------\n",
    "\n",
    "将一个Torch张量转换成一个NumPy阵列，反之亦然。\n",
    "\n",
    "Torch张量和NumPy阵列将共享它们的底层内存位置，改变一个则另一个会随之改变。\n",
    "\n",
    "将一个Torch张量转换成一个NumPy阵列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  1.,  1.,  1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看numpy数组是如何在值中改变的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  2.,  2.,  2.,  2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting NumPy Array to Torch Tensor\n",
    "\n",
    "将NumPy数组转换成Torch张量\n",
    "\n",
    "See how changing the np array changed the Torch Tensor automatically\n",
    "\n",
    "看看如何把np阵列自动变成了Torch张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2.  2.  2.]\n",
      "tensor([ 2.,  2.,  2.,  2.,  2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
    "\n",
    "CPU上所有的张量（除了CharTensor）支持转换为NumPy和转回。\n",
    "\n",
    "CUDA Tensors CUDA张量\n",
    "------------\n",
    "\n",
    "Tensors can be moved onto any device using the ``.to`` method.\n",
    "\n",
    "使用``.to``方法可以把张量移动到任何设备上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.0499], device='cuda:0')\n",
      "tensor([ 2.0499], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0499], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0499], dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.to(\"cpu\", torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0499])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.to(\"cpu\", torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0499], dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.to(\"cpu\", torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
