{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch: Control Flow + Weight Sharing\n",
    "--------------------------------------\n",
    "\n",
    "To showcase the power of PyTorch dynamic graphs, we will implement a very strange\n",
    "model: a fully-connected ReLU network that on each forward pass randomly chooses\n",
    "a number between 1 and 4 and has that many hidden layers, reusing the same\n",
    "weights multiple times to compute the innermost hidden layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 684.8455810546875\n",
      "1 715.6790771484375\n",
      "2 680.0076904296875\n",
      "3 683.5552978515625\n",
      "4 677.4606323242188\n",
      "5 668.28466796875\n",
      "6 652.6633911132812\n",
      "7 668.4595947265625\n",
      "8 491.0012512207031\n",
      "9 650.9712524414062\n",
      "10 646.75048828125\n",
      "11 657.6286010742188\n",
      "12 380.71978759765625\n",
      "13 346.2368469238281\n",
      "14 590.6543579101562\n",
      "15 626.5357666015625\n",
      "16 234.5246124267578\n",
      "17 614.5545043945312\n",
      "18 544.4700317382812\n",
      "19 521.798583984375\n",
      "20 630.9016723632812\n",
      "21 623.3340454101562\n",
      "22 432.3409729003906\n",
      "23 600.044189453125\n",
      "24 582.3042602539062\n",
      "25 337.1929931640625\n",
      "26 534.210693359375\n",
      "27 164.92201232910156\n",
      "28 259.1739807128906\n",
      "29 391.61859130859375\n",
      "30 360.3932189941406\n",
      "31 200.52752685546875\n",
      "32 184.99545288085938\n",
      "33 268.5693054199219\n",
      "34 318.0976867675781\n",
      "35 141.74195861816406\n",
      "36 270.9896545410156\n",
      "37 230.8187713623047\n",
      "38 152.89410400390625\n",
      "39 167.7162322998047\n",
      "40 148.23609924316406\n",
      "41 170.6865997314453\n",
      "42 138.9336700439453\n",
      "43 118.53469848632812\n",
      "44 135.08352661132812\n",
      "45 206.50604248046875\n",
      "46 96.02307891845703\n",
      "47 74.87466430664062\n",
      "48 54.3455924987793\n",
      "49 120.68275451660156\n",
      "50 50.4146614074707\n",
      "51 45.926849365234375\n",
      "52 101.87802124023438\n",
      "53 88.86204528808594\n",
      "54 74.41633605957031\n",
      "55 61.97154998779297\n",
      "56 38.74877166748047\n",
      "57 90.47933959960938\n",
      "58 74.30781555175781\n",
      "59 56.16129684448242\n",
      "60 315.7286071777344\n",
      "61 229.27249145507812\n",
      "62 120.424072265625\n",
      "63 33.90403366088867\n",
      "64 208.89865112304688\n",
      "65 312.5122375488281\n",
      "66 248.77627563476562\n",
      "67 310.4569091796875\n",
      "68 249.8813018798828\n",
      "69 265.1527404785156\n",
      "70 152.97825622558594\n",
      "71 52.094818115234375\n",
      "72 86.53298950195312\n",
      "73 103.22893524169922\n",
      "74 121.66514587402344\n",
      "75 201.56192016601562\n",
      "76 173.20672607421875\n",
      "77 63.24355697631836\n",
      "78 126.08687591552734\n",
      "79 93.26609802246094\n",
      "80 74.03331756591797\n",
      "81 107.66070556640625\n",
      "82 69.41445922851562\n",
      "83 51.57096862792969\n",
      "84 43.66233444213867\n",
      "85 34.69183349609375\n",
      "86 54.838523864746094\n",
      "87 100.40164947509766\n",
      "88 30.357927322387695\n",
      "89 25.710304260253906\n",
      "90 43.25423812866211\n",
      "91 56.40455627441406\n",
      "92 30.519145965576172\n",
      "93 22.913169860839844\n",
      "94 20.20152473449707\n",
      "95 20.177032470703125\n",
      "96 25.904178619384766\n",
      "97 23.68304443359375\n",
      "98 21.054689407348633\n",
      "99 45.89936447143555\n",
      "100 10.281566619873047\n",
      "101 27.003189086914062\n",
      "102 26.482074737548828\n",
      "103 25.34574317932129\n",
      "104 17.302473068237305\n",
      "105 31.6778564453125\n",
      "106 8.581809997558594\n",
      "107 12.30324649810791\n",
      "108 30.46896743774414\n",
      "109 53.69570541381836\n",
      "110 21.943363189697266\n",
      "111 35.98192596435547\n",
      "112 22.166748046875\n",
      "113 22.344511032104492\n",
      "114 21.703649520874023\n",
      "115 13.923408508300781\n",
      "116 17.74366569519043\n",
      "117 15.383213996887207\n",
      "118 13.32505989074707\n",
      "119 9.649703025817871\n",
      "120 13.660324096679688\n",
      "121 10.910055160522461\n",
      "122 9.87989330291748\n",
      "123 9.629779815673828\n",
      "124 9.508991241455078\n",
      "125 9.550507545471191\n",
      "126 7.312644958496094\n",
      "127 4.708027362823486\n",
      "128 4.341503620147705\n",
      "129 14.261157989501953\n",
      "130 3.8604280948638916\n",
      "131 10.595203399658203\n",
      "132 9.535456657409668\n",
      "133 8.54339599609375\n",
      "134 8.264639854431152\n",
      "135 7.389296054840088\n",
      "136 5.979650497436523\n",
      "137 4.659481048583984\n",
      "138 6.720775604248047\n",
      "139 5.769142150878906\n",
      "140 4.605505466461182\n",
      "141 12.186306953430176\n",
      "142 4.24772834777832\n",
      "143 8.4979887008667\n",
      "144 6.897671699523926\n",
      "145 5.530284404754639\n",
      "146 3.92598819732666\n",
      "147 8.023320198059082\n",
      "148 2.3891286849975586\n",
      "149 4.263642311096191\n",
      "150 6.1701436042785645\n",
      "151 3.1592049598693848\n",
      "152 2.2195169925689697\n",
      "153 2.464042901992798\n",
      "154 2.5661351680755615\n",
      "155 2.320225715637207\n",
      "156 3.250166416168213\n",
      "157 7.5937113761901855\n",
      "158 4.5841755867004395\n",
      "159 8.224828720092773\n",
      "160 8.01589298248291\n",
      "161 11.05400562286377\n",
      "162 5.199041843414307\n",
      "163 4.297476768493652\n",
      "164 6.980927467346191\n",
      "165 5.518244743347168\n",
      "166 3.141958713531494\n",
      "167 6.7133469581604\n",
      "168 4.014346122741699\n",
      "169 2.459005117416382\n",
      "170 5.079102039337158\n",
      "171 5.2300238609313965\n",
      "172 2.498541831970215\n",
      "173 3.337881088256836\n",
      "174 3.574037551879883\n",
      "175 5.621417999267578\n",
      "176 3.266242265701294\n",
      "177 3.214226484298706\n",
      "178 1.6704665422439575\n",
      "179 5.483674049377441\n",
      "180 1.4635714292526245\n",
      "181 4.127882957458496\n",
      "182 2.6149420738220215\n",
      "183 2.7452852725982666\n",
      "184 4.804609775543213\n",
      "185 3.049570083618164\n",
      "186 2.327346086502075\n",
      "187 1.6862456798553467\n",
      "188 1.3053981065750122\n",
      "189 2.478996515274048\n",
      "190 1.6014248132705688\n",
      "191 2.408231735229492\n",
      "192 1.2548961639404297\n",
      "193 2.7484676837921143\n",
      "194 0.5420899391174316\n",
      "195 1.9115033149719238\n",
      "196 1.7878514528274536\n",
      "197 4.232391834259033\n",
      "198 0.7881637215614319\n",
      "199 0.8253754377365112\n",
      "200 0.8169125914573669\n",
      "201 6.0517706871032715\n",
      "202 2.5187838077545166\n",
      "203 2.406287431716919\n",
      "204 2.4591612815856934\n",
      "205 2.3496999740600586\n",
      "206 1.9540441036224365\n",
      "207 2.450610399246216\n",
      "208 0.8331998586654663\n",
      "209 2.9304444789886475\n",
      "210 2.0941202640533447\n",
      "211 1.950927972793579\n",
      "212 0.6328986883163452\n",
      "213 1.4398244619369507\n",
      "214 1.6050177812576294\n",
      "215 1.4013510942459106\n",
      "216 2.652749538421631\n",
      "217 0.6559911966323853\n",
      "218 4.581548690795898\n",
      "219 0.48194652795791626\n",
      "220 1.3883247375488281\n",
      "221 2.104929208755493\n",
      "222 1.2186689376831055\n",
      "223 1.1508978605270386\n",
      "224 1.895081639289856\n",
      "225 1.2879717350006104\n",
      "226 1.4774943590164185\n",
      "227 1.5989443063735962\n",
      "228 1.321757435798645\n",
      "229 1.4901317358016968\n",
      "230 1.1748626232147217\n",
      "231 1.2247487306594849\n",
      "232 1.299642562866211\n",
      "233 0.7573500275611877\n",
      "234 0.5844986438751221\n",
      "235 0.4354073107242584\n",
      "236 0.38348376750946045\n",
      "237 0.4014613628387451\n",
      "238 1.7754472494125366\n",
      "239 1.8566112518310547\n",
      "240 1.7405329942703247\n",
      "241 1.4561502933502197\n",
      "242 2.657686471939087\n",
      "243 1.0229747295379639\n",
      "244 1.6786259412765503\n",
      "245 1.8498307466506958\n",
      "246 0.4557456970214844\n",
      "247 0.9335227608680725\n",
      "248 0.45784392952919006\n",
      "249 0.43772006034851074\n",
      "250 1.680819034576416\n",
      "251 0.2580535411834717\n",
      "252 1.7358522415161133\n",
      "253 1.1770358085632324\n",
      "254 0.3683152496814728\n",
      "255 1.6782485246658325\n",
      "256 1.1979353427886963\n",
      "257 1.5890392065048218\n",
      "258 1.3272799253463745\n",
      "259 0.7497026920318604\n",
      "260 0.8695936799049377\n",
      "261 0.46559107303619385\n",
      "262 1.1444437503814697\n",
      "263 0.3350832462310791\n",
      "264 1.3669452667236328\n",
      "265 0.8402673602104187\n",
      "266 1.1612156629562378\n",
      "267 0.5679656267166138\n",
      "268 0.756199061870575\n",
      "269 0.35839855670928955\n",
      "270 1.2039302587509155\n",
      "271 1.0573221445083618\n",
      "272 0.6053410172462463\n",
      "273 1.2698748111724854\n",
      "274 1.1153225898742676\n",
      "275 0.651656985282898\n",
      "276 0.4559054970741272\n",
      "277 0.3735249936580658\n",
      "278 0.24825163185596466\n",
      "279 0.1587117612361908\n",
      "280 1.2927005290985107\n",
      "281 0.8950708508491516\n",
      "282 0.5256574153900146\n",
      "283 1.4170830249786377\n",
      "284 1.2802878618240356\n",
      "285 1.0696357488632202\n",
      "286 0.4749371111392975\n",
      "287 1.5848904848098755\n",
      "288 1.0927742719650269\n",
      "289 1.2919508218765259\n",
      "290 0.6479662656784058\n",
      "291 1.6271638870239258\n",
      "292 1.5207440853118896\n",
      "293 0.9984185695648193\n",
      "294 2.271153688430786\n",
      "295 1.2541426420211792\n",
      "296 0.9568688869476318\n",
      "297 0.9887027144432068\n",
      "298 2.595111846923828\n",
      "299 4.129878520965576\n",
      "300 1.6075847148895264\n",
      "301 3.3967151641845703\n",
      "302 3.267286777496338\n",
      "303 1.33883798122406\n",
      "304 0.8897789120674133\n",
      "305 0.6415892839431763\n",
      "306 1.1408264636993408\n",
      "307 1.08336341381073\n",
      "308 1.175765872001648\n",
      "309 1.4774994850158691\n",
      "310 0.9085236191749573\n",
      "311 0.8026343584060669\n",
      "312 0.38503319025039673\n",
      "313 4.638595104217529\n",
      "314 1.1620218753814697\n",
      "315 1.950553059577942\n",
      "316 0.29541540145874023\n",
      "317 1.9232933521270752\n",
      "318 1.5109620094299316\n",
      "319 0.6990503668785095\n",
      "320 6.616608142852783\n",
      "321 0.9844556450843811\n",
      "322 4.590058326721191\n",
      "323 3.881220579147339\n",
      "324 2.2566606998443604\n",
      "325 1.6457197666168213\n",
      "326 0.40972596406936646\n",
      "327 18.73774528503418\n",
      "328 2.9384000301361084\n",
      "329 0.2481415569782257\n",
      "330 0.5451050996780396\n",
      "331 2.525501251220703\n",
      "332 2.621985673904419\n",
      "333 4.173289775848389\n",
      "334 3.5774006843566895\n",
      "335 1.0421425104141235\n",
      "336 0.2819344401359558\n",
      "337 1.8512911796569824\n",
      "338 5.394304275512695\n",
      "339 0.8175452947616577\n",
      "340 2.2861533164978027\n",
      "341 0.36374807357788086\n",
      "342 4.25401496887207\n",
      "343 1.0214802026748657\n",
      "344 1.310327172279358\n",
      "345 1.6965051889419556\n",
      "346 0.9829784035682678\n",
      "347 1.0181224346160889\n",
      "348 0.542908787727356\n",
      "349 0.43706488609313965\n",
      "350 0.45556116104125977\n",
      "351 0.46622687578201294\n",
      "352 0.2658449411392212\n",
      "353 0.5967414975166321\n",
      "354 0.5846349000930786\n",
      "355 0.2882174253463745\n",
      "356 0.2755713164806366\n",
      "357 1.1883587837219238\n",
      "358 0.3774770498275757\n",
      "359 0.5298542976379395\n",
      "360 0.5032621026039124\n",
      "361 0.42517197132110596\n",
      "362 0.34142744541168213\n",
      "363 0.28625962138175964\n",
      "364 0.5071706175804138\n",
      "365 1.1045185327529907\n",
      "366 0.266211599111557\n",
      "367 0.9686229825019836\n",
      "368 0.6647995710372925\n",
      "369 0.49500906467437744\n",
      "370 0.554149329662323\n",
      "371 0.21725527942180634\n",
      "372 0.23047848045825958\n",
      "373 0.3073374330997467\n",
      "374 0.2545180022716522\n",
      "375 0.20135633647441864\n",
      "376 0.15750238299369812\n",
      "377 1.234203577041626\n",
      "378 0.35181859135627747\n",
      "379 0.43556225299835205\n",
      "380 1.1579625606536865\n",
      "381 0.4824517071247101\n",
      "382 0.5324368476867676\n",
      "383 1.0298768281936646\n",
      "384 0.29020100831985474\n",
      "385 0.152518168091774\n",
      "386 0.8924775123596191\n",
      "387 0.12508118152618408\n",
      "388 0.31353187561035156\n",
      "389 0.09417185932397842\n",
      "390 0.3685370087623596\n",
      "391 1.1080878973007202\n",
      "392 0.462178111076355\n",
      "393 0.8212177753448486\n",
      "394 1.2990565299987793\n",
      "395 0.5805863738059998\n",
      "396 0.41255104541778564\n",
      "397 0.10108812153339386\n",
      "398 4.121740341186523\n",
      "399 0.3521197736263275\n",
      "400 0.23307757079601288\n",
      "401 3.045006275177002\n",
      "402 0.20636793971061707\n",
      "403 1.7755544185638428\n",
      "404 0.3288685083389282\n",
      "405 0.5396651029586792\n",
      "406 1.4394166469573975\n",
      "407 1.2432100772857666\n",
      "408 0.5643676519393921\n",
      "409 0.4457736909389496\n",
      "410 0.39411431550979614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 0.47666582465171814\n",
      "412 0.09399555623531342\n",
      "413 0.5593478679656982\n",
      "414 0.44827011227607727\n",
      "415 0.12351332604885101\n",
      "416 1.18004310131073\n",
      "417 0.4098416268825531\n",
      "418 0.5684894323348999\n",
      "419 0.8889914751052856\n",
      "420 1.624813437461853\n",
      "421 0.9577195048332214\n",
      "422 1.0328303575515747\n",
      "423 0.34034597873687744\n",
      "424 2.020263433456421\n",
      "425 0.4594763219356537\n",
      "426 0.3217617869377136\n",
      "427 0.29588648676872253\n",
      "428 3.304525375366211\n",
      "429 0.9785993695259094\n",
      "430 3.021498918533325\n",
      "431 1.5116639137268066\n",
      "432 1.6282178163528442\n",
      "433 1.1358128786087036\n",
      "434 2.3062069416046143\n",
      "435 0.9410892128944397\n",
      "436 0.34163859486579895\n",
      "437 4.140970706939697\n",
      "438 1.2594940662384033\n",
      "439 0.6974071860313416\n",
      "440 1.104834794998169\n",
      "441 0.9831544756889343\n",
      "442 0.6095170378684998\n",
      "443 0.6906258463859558\n",
      "444 0.5749287605285645\n",
      "445 0.9768989086151123\n",
      "446 0.5293078422546387\n",
      "447 0.7490023374557495\n",
      "448 0.7101702094078064\n",
      "449 0.5341802835464478\n",
      "450 0.5009061694145203\n",
      "451 0.5524845719337463\n",
      "452 0.42883118987083435\n",
      "453 0.29929524660110474\n",
      "454 0.7004864811897278\n",
      "455 0.33200427889823914\n",
      "456 0.7992178797721863\n",
      "457 0.49039146304130554\n",
      "458 0.7529952526092529\n",
      "459 0.3725285232067108\n",
      "460 0.0868380218744278\n",
      "461 2.294574022293091\n",
      "462 0.23150984942913055\n",
      "463 0.5127312541007996\n",
      "464 0.3664577901363373\n",
      "465 0.1233600452542305\n",
      "466 0.13182342052459717\n",
      "467 0.40147864818573\n",
      "468 0.32088786363601685\n",
      "469 1.8278474807739258\n",
      "470 0.6573883295059204\n",
      "471 1.016308307647705\n",
      "472 2.063890218734741\n",
      "473 0.7838385701179504\n",
      "474 0.35505571961402893\n",
      "475 0.47816917300224304\n",
      "476 0.6500005125999451\n",
      "477 0.6284341216087341\n",
      "478 0.4031643569469452\n",
      "479 0.9100589156150818\n",
      "480 0.3103197515010834\n",
      "481 0.2643681764602661\n",
      "482 1.3240588903427124\n",
      "483 0.15403932332992554\n",
      "484 0.30889564752578735\n",
      "485 0.31337296962738037\n",
      "486 0.31804439425468445\n",
      "487 0.1253521740436554\n",
      "488 0.3075495958328247\n",
      "489 0.28738075494766235\n",
      "490 0.24248862266540527\n",
      "491 0.20013585686683655\n",
      "492 0.10592073947191238\n",
      "493 0.6987274289131165\n",
      "494 0.1377330720424652\n",
      "495 0.5128195285797119\n",
      "496 0.4822622239589691\n",
      "497 0.1052793562412262\n",
      "498 0.45754632353782654\n",
      "499 0.08134784549474716\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
