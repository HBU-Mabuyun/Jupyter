{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本节课目标：搭建神经网络，总结搭建八股"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 Tensorflow 的 NN ：\n",
    "用张量表示数据，计算图搭建神经网络，会话执行计算图，优化线上的权重，得到模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量：多维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1.0,2.0])\n",
    "b = tf.constant([2.0,3.0])\n",
    "result = a + b\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算图：搭建神经网络的计算过程，是承载一个或多个计算节点的一张图，只搭建网络，不运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1.0,2.0]])\n",
    "w = tf.constant([[3.0],[4.0]])\n",
    "y = tf.matmul(x,w)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print (sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络的搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 准备数据集，提取特征，作为输入喂给NN\n",
    "2. 搭建NN结构，从输入到输出（先搭建计算图，再用会话执行）\n",
    "3. 大量特征数据喂给NN，迭代优化NN参数\n",
    "4. 使用训练好的模型预测和分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32,shape=(None,2))\n",
    "w1 = tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.0904665]]\n"
     ]
    }
   ],
   "source": [
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y,feed_dict={x:[[0.7,0.5]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.0904665 ]\n",
      " [ 1.2236414 ]\n",
      " [ 1.72707319]\n",
      " [ 2.23050475]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y,feed_dict={x:[[0.7,0.5],[0.2,0.3],[0.3,0.4],[0.4,0.5]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数loss\n",
    "梯度下降 momentum优化 adam优化\n",
    "均方误差MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例子(TF八股文，老师要求背下来)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #0导入模块，生成模拟数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "BATCH_SIZE = 8\n",
    "SEED = 23455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于seed产生随机数\n",
    "rdm = np.random.RandomState(SEED)\n",
    "#随机数返回32行2列的矩阵 表示32组 体积和重量 作为输入数据集\n",
    "X = rdm.rand(32,2)\n",
    "#从X这个32行2列的矩阵中 取出一行 判断如果和小于1 给Y赋值1 如果和不小于1 给Y赋值0 \n",
    "#作为输入数据集的标签（正确答案） \n",
    "Y_ = [[int(x0 + x1 < 1)] for (x0, x1) in X]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1定义神经网络的输入、参数和输出,定义前向传播过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_= tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "w1= tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2定义损失函数及反向传播方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mse = tf.reduce_mean(tf.square(y-y_)) \n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss_mse)\n",
    "#train_step = tf.train.MomentumOptimizer(0.001,0.9).minimize(loss_mse)\n",
    "#train_step = tf.train.AdamOptimizer(0.001).minimize(loss_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3生成会话，训练STEPS轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:\n",
      " [[-0.81131822  1.48459876  0.06532937]\n",
      " [-2.4427042   0.0992484   0.59122431]]\n",
      "w2:\n",
      " [[-0.81131822]\n",
      " [ 1.48459876]\n",
      " [ 0.06532937]]\n",
      "\n",
      "\n",
      "After 0 training step(s), loss_mse on all data is 5.13118\n",
      "After 500 training step(s), loss_mse on all data is 0.429111\n",
      "After 1000 training step(s), loss_mse on all data is 0.409789\n",
      "After 1500 training step(s), loss_mse on all data is 0.399923\n",
      "After 2000 training step(s), loss_mse on all data is 0.394146\n",
      "After 2500 training step(s), loss_mse on all data is 0.390597\n",
      "After 3000 training step(s), loss_mse on all data is 0.388336\n",
      "After 3500 training step(s), loss_mse on all data is 0.386855\n",
      "After 4000 training step(s), loss_mse on all data is 0.385863\n",
      "After 4500 training step(s), loss_mse on all data is 0.385187\n",
      "After 5000 training step(s), loss_mse on all data is 0.384719\n",
      "After 5500 training step(s), loss_mse on all data is 0.384391\n",
      "After 6000 training step(s), loss_mse on all data is 0.38416\n",
      "After 6500 training step(s), loss_mse on all data is 0.383995\n",
      "After 7000 training step(s), loss_mse on all data is 0.383877\n",
      "After 7500 training step(s), loss_mse on all data is 0.383791\n",
      "After 8000 training step(s), loss_mse on all data is 0.383729\n",
      "After 8500 training step(s), loss_mse on all data is 0.383684\n",
      "After 9000 training step(s), loss_mse on all data is 0.383652\n",
      "After 9500 training step(s), loss_mse on all data is 0.383628\n",
      "\n",
      "\n",
      "w1:\n",
      " [[-0.69167352  0.81592691  0.09629341]\n",
      " [-2.34338474 -0.10742698  0.58547068]]\n",
      "w2:\n",
      " [[-0.08710446]\n",
      " [ 0.81644469]\n",
      " [-0.05229824]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    # 输出目前（未经训练）的参数取值。\n",
    "    print (\"w1:\\n\", sess.run(w1))\n",
    "    print (\"w2:\\n\", sess.run(w2))\n",
    "    print (\"\\n\")\n",
    "    \n",
    "    # 训练模型。\n",
    "    STEPS = 10000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*BATCH_SIZE) % 32\n",
    "        end = start + BATCH_SIZE\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y_[start:end]})\n",
    "        if i % 500 == 0:\n",
    "            total_loss = sess.run(loss_mse, feed_dict={x: X, y_: Y_})\n",
    "            print(\"After %d training step(s), loss_mse on all data is %g\" % (i, total_loss))\n",
    "    \n",
    "    # 输出训练后的参数取值。\n",
    "    print (\"\\n\")\n",
    "    print( \"w1:\\n\", sess.run(w1))\n",
    "    print (\"w2:\\n\", sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
