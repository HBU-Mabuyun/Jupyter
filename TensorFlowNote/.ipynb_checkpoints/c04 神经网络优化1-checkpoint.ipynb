{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training steps, w1 is: \n",
      "[[-0.80974597]\n",
      " [ 1.48529029]] \n",
      "\n",
      "After 500 training steps, w1 is: \n",
      "[[-0.46074435]\n",
      " [ 1.64187801]] \n",
      "\n",
      "After 1000 training steps, w1 is: \n",
      "[[-0.21939856]\n",
      " [ 1.69847655]] \n",
      "\n",
      "After 1500 training steps, w1 is: \n",
      "[[-0.04415595]\n",
      " [ 1.70031762]] \n",
      "\n",
      "After 2000 training steps, w1 is: \n",
      "[[ 0.08942621]\n",
      " [ 1.67332804]] \n",
      "\n",
      "After 2500 training steps, w1 is: \n",
      "[[ 0.19583555]\n",
      " [ 1.63226771]] \n",
      "\n",
      "After 3000 training steps, w1 is: \n",
      "[[ 0.28375748]\n",
      " [ 1.58544338]] \n",
      "\n",
      "After 3500 training steps, w1 is: \n",
      "[[ 0.35848638]\n",
      " [ 1.53744721]] \n",
      "\n",
      "After 4000 training steps, w1 is: \n",
      "[[ 0.42332518]\n",
      " [ 1.49073935]] \n",
      "\n",
      "After 4500 training steps, w1 is: \n",
      "[[ 0.48040026]\n",
      " [ 1.4465574 ]] \n",
      "\n",
      "After 5000 training steps, w1 is: \n",
      "[[ 0.53113604]\n",
      " [ 1.40545356]] \n",
      "\n",
      "After 5500 training steps, w1 is: \n",
      "[[ 0.57653248]\n",
      " [ 1.36759412]] \n",
      "\n",
      "After 6000 training steps, w1 is: \n",
      "[[ 0.61732584]\n",
      " [ 1.33294034]] \n",
      "\n",
      "After 6500 training steps, w1 is: \n",
      "[[ 0.65408462]\n",
      " [ 1.30134261]] \n",
      "\n",
      "After 7000 training steps, w1 is: \n",
      "[[ 0.6872685 ]\n",
      " [ 1.27260196]] \n",
      "\n",
      "After 7500 training steps, w1 is: \n",
      "[[ 0.71725976]\n",
      " [ 1.24650049]] \n",
      "\n",
      "After 8000 training steps, w1 is: \n",
      "[[ 0.74438608]\n",
      " [ 1.22281969]] \n",
      "\n",
      "After 8500 training steps, w1 is: \n",
      "[[ 0.7689324]\n",
      " [ 1.2013483]] \n",
      "\n",
      "After 9000 training steps, w1 is: \n",
      "[[ 0.79115134]\n",
      " [ 1.18188894]] \n",
      "\n",
      "After 9500 training steps, w1 is: \n",
      "[[ 0.81126702]\n",
      " [ 1.16425669]] \n",
      "\n",
      "After 10000 training steps, w1 is: \n",
      "[[ 0.82948142]\n",
      " [ 1.14828289]] \n",
      "\n",
      "After 10500 training steps, w1 is: \n",
      "[[ 0.84597576]\n",
      " [ 1.13381255]] \n",
      "\n",
      "After 11000 training steps, w1 is: \n",
      "[[ 0.8609128 ]\n",
      " [ 1.12070608]] \n",
      "\n",
      "After 11500 training steps, w1 is: \n",
      "[[ 0.87444043]\n",
      " [ 1.10883462]] \n",
      "\n",
      "After 12000 training steps, w1 is: \n",
      "[[ 0.88669145]\n",
      " [ 1.09808242]] \n",
      "\n",
      "After 12500 training steps, w1 is: \n",
      "[[ 0.89778632]\n",
      " [ 1.08834386]] \n",
      "\n",
      "After 13000 training steps, w1 is: \n",
      "[[ 0.90783483]\n",
      " [ 1.07952428]] \n",
      "\n",
      "After 13500 training steps, w1 is: \n",
      "[[ 0.91693527]\n",
      " [ 1.0715363 ]] \n",
      "\n",
      "After 14000 training steps, w1 is: \n",
      "[[ 0.92517716]\n",
      " [ 1.06430185]] \n",
      "\n",
      "After 14500 training steps, w1 is: \n",
      "[[ 0.93264157]\n",
      " [ 1.05774975]] \n",
      "\n",
      "After 15000 training steps, w1 is: \n",
      "[[ 0.93940228]\n",
      " [ 1.05181527]] \n",
      "\n",
      "After 15500 training steps, w1 is: \n",
      "[[ 0.94552511]\n",
      " [ 1.0464406 ]] \n",
      "\n",
      "After 16000 training steps, w1 is: \n",
      "[[ 0.95107025]\n",
      " [ 1.04157281]] \n",
      "\n",
      "After 16500 training steps, w1 is: \n",
      "[[ 0.95609277]\n",
      " [ 1.03716397]] \n",
      "\n",
      "After 17000 training steps, w1 is: \n",
      "[[ 0.96064115]\n",
      " [ 1.03317142]] \n",
      "\n",
      "After 17500 training steps, w1 is: \n",
      "[[ 0.96476096]\n",
      " [ 1.02955461]] \n",
      "\n",
      "After 18000 training steps, w1 is: \n",
      "[[ 0.96849167]\n",
      " [ 1.02628016]] \n",
      "\n",
      "After 18500 training steps, w1 is: \n",
      "[[ 0.97187072]\n",
      " [ 1.02331424]] \n",
      "\n",
      "After 19000 training steps, w1 is: \n",
      "[[ 0.974931  ]\n",
      " [ 1.02062762]] \n",
      "\n",
      "After 19500 training steps, w1 is: \n",
      "[[ 0.97770262]\n",
      " [ 1.01819491]] \n",
      "\n",
      "Final w1 is: \n",
      " [[ 0.98019385]\n",
      " [ 1.01598072]]\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "#预测多或预测少的影响一样\n",
    "#0导入模块，生成数据集\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "BATCH_SIZE = 8\n",
    "SEED = 23455\n",
    "\n",
    "rdm = np.random.RandomState(SEED)\n",
    "X = rdm.rand(32,2)\n",
    "Y_ = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1, x2) in X]\n",
    "\n",
    "#1定义神经网络的输入、参数和输出，定义前向传播过程。\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "w1= tf.Variable(tf.random_normal([2, 1], stddev=1, seed=1))\n",
    "y = tf.matmul(x, w1)\n",
    "\n",
    "#2定义损失函数及反向传播方法。\n",
    "#定义损失函数为MSE,反向传播方法为梯度下降。\n",
    "loss_mse = tf.reduce_mean(tf.square(y_ - y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss_mse)\n",
    "\n",
    "#3生成会话，训练STEPS轮\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    STEPS = 20000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*BATCH_SIZE) % 32\n",
    "        end = (i*BATCH_SIZE) % 32 + BATCH_SIZE\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y_[start:end]})\n",
    "        if i % 500 == 0:\n",
    "            print (\"After %d training steps, w1 is: \" % (i))\n",
    "            print (sess.run(w1), \"\\n\")\n",
    "    print (\"Final w1 is: \\n\", sess.run(w1))\n",
    "#在本代码#2中尝试其他反向传播方法，看对收敛速度的影响，把体会写到笔记中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
