{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all files from a directory in a DataFrame.\n",
    "\n",
    "在DataFrame中从目录加载所有文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_directory_data(directory):\n",
    "  data = {}\n",
    "  data[\"sentence\"] = []\n",
    "  data[\"sentiment\"] = []\n",
    "  for file_path in os.listdir(directory):\n",
    "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "      data[\"sentence\"].append(f.read())\n",
    "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "  return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge positive and negative examples, add a polarity column and shuffle.\n",
    "\n",
    "合并正例和负例，加入极性列和搅乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory):\n",
    "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "  pos_df[\"polarity\"] = 1\n",
    "  neg_df[\"polarity\"] = 0\n",
    "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce logging output.\n",
    "\n",
    "减少日志输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and process the dataset files.\n",
    "\n",
    "下载并处理数据集文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 下面这句执行超级慢！ 每次都下载么？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.utils.get_file(fname=\"aclImdb.tar.gz\", \n",
    "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", extract=True)\n",
    "        # Downloads a file from a URL if it not already in the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\David\\\\.keras\\\\datasets\\\\aclImdb.tar.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataset(os.path.join(os.path.dirname(dataset),\"aclImdb\", \"train\"))\n",
    "test_df = load_dataset(os.path.join(os.path.dirname(dataset),\"aclImdb\", \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In the world of old-school kung fu movies, wh...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everyone has a first love, and though it is ha...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steely, powerful gangster supreme Frankie Diom...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ye Lou's film Purple Butterfly pits a secret o...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is very underrated. It's highly ima...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  polarity\n",
       "0  \"In the world of old-school kung fu movies, wh...         8         1\n",
       "1  Everyone has a first love, and though it is ha...         8         1\n",
       "2  Steely, powerful gangster supreme Frankie Diom...         8         1\n",
       "3  Ye Lou's film Purple Butterfly pits a secret o...         2         0\n",
       "4  This movie is very underrated. It's highly ima...        10         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"The Falcon and the Snowman\" is the story of t...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No, this has nothing to do with the sitcom \"Se...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not as bad as \"Billy Bathgate\" but close. Try ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am very interested in animal children and I ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In this offering, one only has to view the cur...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  polarity\n",
       "0  \"The Falcon and the Snowman\" is the story of t...         7         1\n",
       "1  No, this has nothing to do with the sitcom \"Se...        10         1\n",
       "2  Not as bad as \"Billy Bathgate\" but close. Try ...         2         0\n",
       "3  I am very interested in animal children and I ...         2         0\n",
       "4  In this offering, one only has to view the cur...        10         1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(train_df, train_df[\"polarity\"], num_epochs=None, shuffle=True)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(train_df, train_df[\"polarity\"], shuffle=False)\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(test_df, test_df[\"polarity\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature columns （访问速度非常慢，FK）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "    key=\"sentence\", \n",
    "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[500, 100],\n",
    "    feature_columns=[embedded_text_feature_column],\n",
    "    n_classes=2,\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for 1,000 steps means 128,000 training examples with the default\n",
    "# batch size. This is roughly equivalent to 5 epochs since the training dataset\n",
    "# contains 25,000 examples.\n",
    "estimator.train(input_fn=train_input_fn, steps=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.8021199703216553\n",
      "Test set accuracy: 0.7932000160217285\n"
     ]
    }
   ],
   "source": [
    "train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "print (\"Training set accuracy: {accuracy}\".format(**train_eval_result))\n",
    "print (\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28e28436dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(estimator, input_fn):\n",
    "  return [x[\"class_ids\"][0] for x in estimator.predict(input_fn=input_fn)]\n",
    "\n",
    "LABELS = [\n",
    "    \"negative\", \"positive\"\n",
    "]\n",
    "\n",
    "# Create a confusion matrix on training data.\n",
    "with tf.Graph().as_default():\n",
    "  cm = tf.confusion_matrix(train_df[\"polarity\"],get_predictions(estimator, predict_train_input_fn))\n",
    "  with tf.Session() as session:\n",
    "    cm_out = session.run(cm)\n",
    "\n",
    "# Normalize the confusion matrix so that each row sums to 1.\n",
    "cm_out = cm_out.astype(float) / cm_out.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm_out, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
    "plt.xlabel(\"Predicted\");\n",
    "plt.ylabel(\"True\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced: Transfer learning analysis 迁移学习分析\n",
    "https://www.zhihu.com/question/41979241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[31128] and type string on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/SparseFillEmptyRows = SparseFillEmptyRows[T=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:1, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:2, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/string_to_index_Lookup/hash_bucket/_93 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_dn...ash_bucket\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/SparseFillEmptyRows', defined at:\n  File \"C:\\Users\\David\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-6448af8cc30e>\", line 25, in <module>\n    results[\"nnlm-en-dim128\"] = train_and_evaluate_with_module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n  File \"<ipython-input-16-6448af8cc30e>\", line 14, in train_and_evaluate_with_module\n    test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 417, in evaluate\n    name=name)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 931, in _evaluate_model\n    features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 805, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 354, in _model_fn\n    config=config)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 184, in _dnn_model_fn\n    logits = logit_fn(features=features, mode=mode)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 92, in dnn_logit_fn\n    features=features, feature_columns=feature_columns)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 274, in input_layer\n    trainable, cols_to_vars)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 199, in _internal_input_layer\n    trainable=trainable)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\feature_column.py\", line 156, in _get_dense_tensor\n    return m(text_batch)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\module.py\", line 203, in __call__\n    name=name)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 447, in create_apply_graph\n    restore_collections_predicate=(lambda key: key in import_collections))\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1927, in import_meta_graph\n    **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 741, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 577, in import_graph_def\n    op_def=op_def)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[31128] and type string on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/SparseFillEmptyRows = SparseFillEmptyRows[T=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:1, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:2, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/string_to_index_Lookup/hash_bucket/_93 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_dn...ash_bucket\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[31128] and type string on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/SparseFillEmptyRows = SparseFillEmptyRows[T=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:1, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:2, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/string_to_index_Lookup/hash_bucket/_93 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_dn...ash_bucket\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6448af8cc30e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nnlm-en-dim128\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate_with_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/nnlm-en-dim128/1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"nnlm-en-dim128-with-module-training\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate_with_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/nnlm-en-dim128/1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"random-nnlm-en-dim128\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate_with_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/google/random-nnlm-en-dim128/1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-6448af8cc30e>\u001b[0m in \u001b[0;36mtrain_and_evaluate_with_module\u001b[1;34m(hub_module, train_module)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0mtrain_eval_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_train_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m   \u001b[0mtest_eval_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredict_test_input_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m   \u001b[0mtraining_set_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_eval_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_model\u001b[1;34m(self, input_fn, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    959\u001b[0m           \u001b[0mfinal_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m           config=self._session_config)\n\u001b[0m\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       _write_dict_to_summary(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[1;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m   logging.info('Finished evaluation at ' + time.strftime('%Y-%m-%d-%H:%M:%S',\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    544\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1023\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1096\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[31128] and type string on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/SparseFillEmptyRows = SparseFillEmptyRows[T=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:1, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:2, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/string_to_index_Lookup/hash_bucket/_93 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_dn...ash_bucket\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/SparseFillEmptyRows', defined at:\n  File \"C:\\Users\\David\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-16-6448af8cc30e>\", line 25, in <module>\n    results[\"nnlm-en-dim128\"] = train_and_evaluate_with_module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n  File \"<ipython-input-16-6448af8cc30e>\", line 14, in train_and_evaluate_with_module\n    test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 417, in evaluate\n    name=name)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 931, in _evaluate_model\n    features, labels, model_fn_lib.ModeKeys.EVAL, self.config)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 805, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 354, in _model_fn\n    config=config)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 184, in _dnn_model_fn\n    logits = logit_fn(features=features, mode=mode)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\", line 92, in dnn_logit_fn\n    features=features, feature_columns=feature_columns)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 274, in input_layer\n    trainable, cols_to_vars)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 199, in _internal_input_layer\n    trainable=trainable)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\feature_column.py\", line 156, in _get_dense_tensor\n    return m(text_batch)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\module.py\", line 203, in __call__\n    name=name)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\native_module.py\", line 447, in create_apply_graph\n    restore_collections_predicate=(lambda key: key in import_collections))\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1927, in import_meta_graph\n    **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 741, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 577, in import_graph_def\n    op_def=op_def)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\David\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[31128] and type string on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cuda_host_bfc\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/SparseFillEmptyRows = SparseFillEmptyRows[T=DT_STRING, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:1, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/tokenize/StringSplit:2, dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/SparseFillEmptyRows/Const)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: dnn/input_from_feature_columns/input_layer/sentence_hub_module_embedding/module_apply_default/string_to_index_Lookup/hash_bucket/_93 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_23_dn...ash_bucket\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_with_module(hub_module, train_module=False):\n",
    "  embedded_text_feature_column = hub.text_embedding_column(\n",
    "      key=\"sentence\", module_spec=hub_module, trainable=train_module)\n",
    "\n",
    "  estimator = tf.estimator.DNNClassifier(\n",
    "      hidden_units=[500, 100],\n",
    "      feature_columns=[embedded_text_feature_column],\n",
    "      n_classes=2,\n",
    "      optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "  estimator.train(input_fn=train_input_fn, steps=1000)\n",
    "\n",
    "  train_eval_result = estimator.evaluate(input_fn=predict_train_input_fn)\n",
    "  test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "\n",
    "  training_set_accuracy = train_eval_result[\"accuracy\"]\n",
    "  test_set_accuracy = test_eval_result[\"accuracy\"]\n",
    "\n",
    "  return {\n",
    "      \"Training accuracy\": training_set_accuracy,\n",
    "      \"Test accuracy\": test_set_accuracy\n",
    "  }\n",
    "\n",
    "results = {}\n",
    "results[\"nnlm-en-dim128\"] = train_and_evaluate_with_module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "results[\"nnlm-en-dim128-with-module-training\"] = train_and_evaluate_with_module(\"https://tfhub.dev/google/nnlm-en-dim128/1\", True)\n",
    "results[\"random-nnlm-en-dim128\"] = train_and_evaluate_with_module(\"https://tfhub.dev/google/random-nnlm-en-dim128/1\")\n",
    "results[\"random-nnlm-en-dim128-with-module-training\"] = train_and_evaluate_with_module(\"https://tfhub.dev/google/random-nnlm-en-dim128/1\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(results, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.evaluate(input_fn=predict_test_input_fn)[\"accuracy_baseline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上次更新日期：四月 6, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
