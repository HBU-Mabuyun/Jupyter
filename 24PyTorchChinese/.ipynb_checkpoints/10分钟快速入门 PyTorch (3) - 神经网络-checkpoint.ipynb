{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.pytorchtutorial.com/10-minute-pytorch-3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下载训练集 MNIST 手写数字训练集\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义简单的前馈神经网络\n",
    "class Neuralnetwork(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Neuralnetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Neuralnetwork(28 * 28, 300, 100, 10)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "**********\n",
      "[1/50] Loss: 0.237788, Acc: 0.933125\n",
      "[1/50] Loss: 0.245343, Acc: 0.932344\n",
      "[1/50] Loss: 0.240234, Acc: 0.933438\n",
      "[1/50] Loss: 0.242141, Acc: 0.932682\n",
      "[1/50] Loss: 0.244409, Acc: 0.932396\n",
      "[1/50] Loss: 0.244044, Acc: 0.932413\n",
      "Finish 1 epoch, Loss: 0.244486, Acc: 0.932533\n",
      "Test Loss: 0.274259, Acc: 0.924700\n",
      "\n",
      "epoch 2\n",
      "**********\n",
      "[2/50] Loss: 0.237184, Acc: 0.935104\n",
      "[2/50] Loss: 0.240332, Acc: 0.932969\n",
      "[2/50] Loss: 0.241020, Acc: 0.933924\n",
      "[2/50] Loss: 0.240444, Acc: 0.933073\n",
      "[2/50] Loss: 0.241933, Acc: 0.933125\n",
      "[2/50] Loss: 0.244858, Acc: 0.931927\n",
      "Finish 2 epoch, Loss: 0.244147, Acc: 0.932283\n",
      "Test Loss: 0.272003, Acc: 0.925600\n",
      "\n",
      "epoch 3\n",
      "**********\n",
      "[3/50] Loss: 0.234901, Acc: 0.933438\n",
      "[3/50] Loss: 0.243816, Acc: 0.932187\n",
      "[3/50] Loss: 0.245799, Acc: 0.932743\n",
      "[3/50] Loss: 0.243145, Acc: 0.933151\n",
      "[3/50] Loss: 0.244990, Acc: 0.932521\n",
      "[3/50] Loss: 0.245071, Acc: 0.932552\n",
      "Finish 3 epoch, Loss: 0.243823, Acc: 0.932867\n",
      "Test Loss: 0.271601, Acc: 0.925500\n",
      "\n",
      "epoch 4\n",
      "**********\n",
      "[4/50] Loss: 0.244800, Acc: 0.931667\n",
      "[4/50] Loss: 0.239706, Acc: 0.934635\n",
      "[4/50] Loss: 0.242233, Acc: 0.932951\n",
      "[4/50] Loss: 0.236635, Acc: 0.934063\n",
      "[4/50] Loss: 0.239203, Acc: 0.933312\n",
      "[4/50] Loss: 0.243632, Acc: 0.932517\n",
      "Finish 4 epoch, Loss: 0.243555, Acc: 0.932600\n",
      "Test Loss: 0.275042, Acc: 0.922500\n",
      "\n",
      "epoch 5\n",
      "**********\n",
      "[5/50] Loss: 0.226586, Acc: 0.937708\n",
      "[5/50] Loss: 0.236383, Acc: 0.934427\n",
      "[5/50] Loss: 0.240633, Acc: 0.932361\n",
      "[5/50] Loss: 0.244231, Acc: 0.931953\n",
      "[5/50] Loss: 0.244089, Acc: 0.932458\n",
      "[5/50] Loss: 0.242955, Acc: 0.933003\n",
      "Finish 5 epoch, Loss: 0.243074, Acc: 0.933033\n",
      "Test Loss: 0.271225, Acc: 0.925000\n",
      "\n",
      "epoch 6\n",
      "**********\n",
      "[6/50] Loss: 0.250090, Acc: 0.931771\n",
      "[6/50] Loss: 0.246512, Acc: 0.932083\n",
      "[6/50] Loss: 0.243282, Acc: 0.933056\n",
      "[6/50] Loss: 0.246901, Acc: 0.932109\n",
      "[6/50] Loss: 0.246287, Acc: 0.931979\n",
      "[6/50] Loss: 0.242795, Acc: 0.932604\n",
      "Finish 6 epoch, Loss: 0.243224, Acc: 0.932617\n",
      "Test Loss: 0.274812, Acc: 0.925100\n",
      "\n",
      "epoch 7\n",
      "**********\n",
      "[7/50] Loss: 0.244293, Acc: 0.928854\n",
      "[7/50] Loss: 0.245456, Acc: 0.931042\n",
      "[7/50] Loss: 0.247290, Acc: 0.932153\n",
      "[7/50] Loss: 0.247698, Acc: 0.932500\n",
      "[7/50] Loss: 0.242805, Acc: 0.933063\n",
      "[7/50] Loss: 0.242301, Acc: 0.933108\n",
      "Finish 7 epoch, Loss: 0.243065, Acc: 0.932983\n",
      "Test Loss: 0.268683, Acc: 0.926000\n",
      "\n",
      "epoch 8\n",
      "**********\n",
      "[8/50] Loss: 0.252376, Acc: 0.930937\n",
      "[8/50] Loss: 0.242361, Acc: 0.934010\n",
      "[8/50] Loss: 0.244900, Acc: 0.932083\n",
      "[8/50] Loss: 0.244481, Acc: 0.932760\n",
      "[8/50] Loss: 0.241925, Acc: 0.933417\n",
      "[8/50] Loss: 0.241698, Acc: 0.933385\n",
      "Finish 8 epoch, Loss: 0.242395, Acc: 0.933217\n",
      "Test Loss: 0.272347, Acc: 0.924900\n",
      "\n",
      "epoch 9\n",
      "**********\n",
      "[9/50] Loss: 0.245379, Acc: 0.931458\n",
      "[9/50] Loss: 0.234229, Acc: 0.933333\n",
      "[9/50] Loss: 0.235249, Acc: 0.933958\n",
      "[9/50] Loss: 0.237949, Acc: 0.933542\n",
      "[9/50] Loss: 0.237461, Acc: 0.933667\n",
      "[9/50] Loss: 0.241810, Acc: 0.933073\n",
      "Finish 9 epoch, Loss: 0.242451, Acc: 0.932550\n",
      "Test Loss: 0.271512, Acc: 0.926500\n",
      "\n",
      "epoch 10\n",
      "**********\n",
      "[10/50] Loss: 0.239777, Acc: 0.931667\n",
      "[10/50] Loss: 0.234279, Acc: 0.934896\n",
      "[10/50] Loss: 0.239702, Acc: 0.934063\n",
      "[10/50] Loss: 0.240047, Acc: 0.934427\n",
      "[10/50] Loss: 0.240401, Acc: 0.933813\n",
      "[10/50] Loss: 0.241270, Acc: 0.932986\n",
      "Finish 10 epoch, Loss: 0.242510, Acc: 0.932450\n",
      "Test Loss: 0.276278, Acc: 0.922400\n",
      "\n",
      "epoch 11\n",
      "**********\n",
      "[11/50] Loss: 0.229405, Acc: 0.930833\n",
      "[11/50] Loss: 0.233894, Acc: 0.932396\n",
      "[11/50] Loss: 0.240926, Acc: 0.931493\n",
      "[11/50] Loss: 0.238160, Acc: 0.932318\n",
      "[11/50] Loss: 0.239419, Acc: 0.932292\n",
      "[11/50] Loss: 0.241439, Acc: 0.932552\n",
      "Finish 11 epoch, Loss: 0.241918, Acc: 0.932717\n",
      "Test Loss: 0.273789, Acc: 0.924500\n",
      "\n",
      "epoch 12\n",
      "**********\n",
      "[12/50] Loss: 0.251704, Acc: 0.932187\n",
      "[12/50] Loss: 0.239972, Acc: 0.933750\n",
      "[12/50] Loss: 0.239281, Acc: 0.933750\n",
      "[12/50] Loss: 0.240990, Acc: 0.933490\n",
      "[12/50] Loss: 0.242446, Acc: 0.933292\n",
      "[12/50] Loss: 0.240573, Acc: 0.933698\n",
      "Finish 12 epoch, Loss: 0.241526, Acc: 0.933467\n",
      "Test Loss: 0.273505, Acc: 0.925600\n",
      "\n",
      "epoch 13\n",
      "**********\n",
      "[13/50] Loss: 0.236033, Acc: 0.934583\n",
      "[13/50] Loss: 0.239652, Acc: 0.933802\n",
      "[13/50] Loss: 0.242742, Acc: 0.932743\n",
      "[13/50] Loss: 0.244301, Acc: 0.932292\n",
      "[13/50] Loss: 0.244431, Acc: 0.932250\n",
      "[13/50] Loss: 0.241751, Acc: 0.932413\n",
      "Finish 13 epoch, Loss: 0.241630, Acc: 0.932383\n",
      "Test Loss: 0.276349, Acc: 0.923000\n",
      "\n",
      "epoch 14\n",
      "**********\n",
      "[14/50] Loss: 0.229812, Acc: 0.935417\n",
      "[14/50] Loss: 0.225212, Acc: 0.937552\n",
      "[14/50] Loss: 0.232575, Acc: 0.936076\n",
      "[14/50] Loss: 0.233257, Acc: 0.935026\n",
      "[14/50] Loss: 0.236439, Acc: 0.934333\n",
      "[14/50] Loss: 0.241462, Acc: 0.933351\n",
      "Finish 14 epoch, Loss: 0.241522, Acc: 0.933000\n",
      "Test Loss: 0.273370, Acc: 0.924900\n",
      "\n",
      "epoch 15\n",
      "**********\n",
      "[15/50] Loss: 0.238808, Acc: 0.933854\n",
      "[15/50] Loss: 0.241419, Acc: 0.934740\n",
      "[15/50] Loss: 0.242675, Acc: 0.933993\n",
      "[15/50] Loss: 0.242843, Acc: 0.934479\n",
      "[15/50] Loss: 0.241504, Acc: 0.933979\n",
      "[15/50] Loss: 0.242656, Acc: 0.933333\n",
      "Finish 15 epoch, Loss: 0.241503, Acc: 0.933367\n",
      "Test Loss: 0.269520, Acc: 0.925000\n",
      "\n",
      "epoch 16\n",
      "**********\n",
      "[16/50] Loss: 0.231786, Acc: 0.936250\n",
      "[16/50] Loss: 0.230233, Acc: 0.935521\n",
      "[16/50] Loss: 0.234162, Acc: 0.934931\n",
      "[16/50] Loss: 0.238466, Acc: 0.934401\n",
      "[16/50] Loss: 0.241281, Acc: 0.932875\n",
      "[16/50] Loss: 0.241165, Acc: 0.932778\n",
      "Finish 16 epoch, Loss: 0.240845, Acc: 0.932933\n",
      "Test Loss: 0.271987, Acc: 0.925200\n",
      "\n",
      "epoch 17\n",
      "**********\n",
      "[17/50] Loss: 0.233321, Acc: 0.936250\n",
      "[17/50] Loss: 0.228086, Acc: 0.936615\n",
      "[17/50] Loss: 0.233367, Acc: 0.935243\n",
      "[17/50] Loss: 0.236047, Acc: 0.934792\n",
      "[17/50] Loss: 0.239939, Acc: 0.934021\n",
      "[17/50] Loss: 0.241365, Acc: 0.933160\n",
      "Finish 17 epoch, Loss: 0.240837, Acc: 0.933300\n",
      "Test Loss: 0.271133, Acc: 0.925500\n",
      "\n",
      "epoch 18\n",
      "**********\n",
      "[18/50] Loss: 0.241101, Acc: 0.930312\n",
      "[18/50] Loss: 0.238038, Acc: 0.931771\n",
      "[18/50] Loss: 0.235266, Acc: 0.932569\n",
      "[18/50] Loss: 0.234367, Acc: 0.932969\n",
      "[18/50] Loss: 0.241487, Acc: 0.932271\n",
      "[18/50] Loss: 0.240090, Acc: 0.932743\n",
      "Finish 18 epoch, Loss: 0.240532, Acc: 0.932650\n",
      "Test Loss: 0.279180, Acc: 0.923700\n",
      "\n",
      "epoch 19\n",
      "**********\n",
      "[19/50] Loss: 0.221917, Acc: 0.939063\n",
      "[19/50] Loss: 0.233335, Acc: 0.937292\n",
      "[19/50] Loss: 0.235294, Acc: 0.935556\n",
      "[19/50] Loss: 0.236149, Acc: 0.935286\n",
      "[19/50] Loss: 0.240470, Acc: 0.934229\n",
      "[19/50] Loss: 0.239956, Acc: 0.934097\n",
      "Finish 19 epoch, Loss: 0.240345, Acc: 0.933617\n",
      "Test Loss: 0.272001, Acc: 0.927300\n",
      "\n",
      "epoch 20\n",
      "**********\n",
      "[20/50] Loss: 0.239425, Acc: 0.933125\n",
      "[20/50] Loss: 0.241357, Acc: 0.933906\n",
      "[20/50] Loss: 0.239701, Acc: 0.933958\n",
      "[20/50] Loss: 0.239660, Acc: 0.934063\n",
      "[20/50] Loss: 0.237884, Acc: 0.933708\n",
      "[20/50] Loss: 0.239409, Acc: 0.933455\n",
      "Finish 20 epoch, Loss: 0.240111, Acc: 0.933483\n",
      "Test Loss: 0.274587, Acc: 0.926500\n",
      "\n",
      "epoch 21\n",
      "**********\n",
      "[21/50] Loss: 0.216002, Acc: 0.940417\n",
      "[21/50] Loss: 0.231881, Acc: 0.936406\n",
      "[21/50] Loss: 0.237316, Acc: 0.935556\n",
      "[21/50] Loss: 0.237558, Acc: 0.935078\n",
      "[21/50] Loss: 0.236822, Acc: 0.934896\n",
      "[21/50] Loss: 0.238896, Acc: 0.934201\n",
      "Finish 21 epoch, Loss: 0.240198, Acc: 0.933733\n",
      "Test Loss: 0.270990, Acc: 0.925000\n",
      "\n",
      "epoch 22\n",
      "**********\n",
      "[22/50] Loss: 0.226656, Acc: 0.935729\n",
      "[22/50] Loss: 0.238238, Acc: 0.934115\n",
      "[22/50] Loss: 0.236922, Acc: 0.935382\n",
      "[22/50] Loss: 0.236607, Acc: 0.936120\n",
      "[22/50] Loss: 0.238734, Acc: 0.935542\n",
      "[22/50] Loss: 0.239628, Acc: 0.934740\n",
      "Finish 22 epoch, Loss: 0.239786, Acc: 0.934283\n",
      "Test Loss: 0.273801, Acc: 0.926400\n",
      "\n",
      "epoch 23\n",
      "**********\n",
      "[23/50] Loss: 0.232959, Acc: 0.936771\n",
      "[23/50] Loss: 0.238251, Acc: 0.934688\n",
      "[23/50] Loss: 0.244468, Acc: 0.934201\n",
      "[23/50] Loss: 0.238963, Acc: 0.935078\n",
      "[23/50] Loss: 0.238770, Acc: 0.934875\n",
      "[23/50] Loss: 0.239373, Acc: 0.934497\n",
      "Finish 23 epoch, Loss: 0.239836, Acc: 0.934017\n",
      "Test Loss: 0.271604, Acc: 0.925200\n",
      "\n",
      "epoch 24\n",
      "**********\n",
      "[24/50] Loss: 0.230088, Acc: 0.932604\n",
      "[24/50] Loss: 0.241676, Acc: 0.933802\n",
      "[24/50] Loss: 0.239946, Acc: 0.933854\n",
      "[24/50] Loss: 0.238237, Acc: 0.934036\n",
      "[24/50] Loss: 0.235224, Acc: 0.934271\n",
      "[24/50] Loss: 0.239583, Acc: 0.932899\n",
      "Finish 24 epoch, Loss: 0.239561, Acc: 0.933150\n",
      "Test Loss: 0.274856, Acc: 0.924100\n",
      "\n",
      "epoch 25\n",
      "**********\n",
      "[25/50] Loss: 0.240591, Acc: 0.931667\n",
      "[25/50] Loss: 0.242748, Acc: 0.931562\n",
      "[25/50] Loss: 0.240794, Acc: 0.931458\n",
      "[25/50] Loss: 0.241757, Acc: 0.932161\n",
      "[25/50] Loss: 0.239294, Acc: 0.933229\n",
      "[25/50] Loss: 0.240153, Acc: 0.933351\n",
      "Finish 25 epoch, Loss: 0.239672, Acc: 0.933450\n",
      "Test Loss: 0.272614, Acc: 0.924500\n",
      "\n",
      "epoch 26\n",
      "**********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/50] Loss: 0.248396, Acc: 0.930937\n",
      "[26/50] Loss: 0.245133, Acc: 0.933385\n",
      "[26/50] Loss: 0.244195, Acc: 0.933958\n",
      "[26/50] Loss: 0.237315, Acc: 0.934792\n",
      "[26/50] Loss: 0.238330, Acc: 0.934083\n",
      "[26/50] Loss: 0.238493, Acc: 0.934080\n",
      "Finish 26 epoch, Loss: 0.239564, Acc: 0.933783\n",
      "Test Loss: 0.269310, Acc: 0.926200\n",
      "\n",
      "epoch 27\n",
      "**********\n",
      "[27/50] Loss: 0.225791, Acc: 0.937708\n",
      "[27/50] Loss: 0.230410, Acc: 0.937708\n",
      "[27/50] Loss: 0.232581, Acc: 0.935764\n",
      "[27/50] Loss: 0.233523, Acc: 0.935182\n",
      "[27/50] Loss: 0.235778, Acc: 0.934667\n",
      "[27/50] Loss: 0.237747, Acc: 0.934288\n",
      "Finish 27 epoch, Loss: 0.239013, Acc: 0.933950\n",
      "Test Loss: 0.273720, Acc: 0.925300\n",
      "\n",
      "epoch 28\n",
      "**********\n",
      "[28/50] Loss: 0.249180, Acc: 0.930833\n",
      "[28/50] Loss: 0.237613, Acc: 0.932656\n",
      "[28/50] Loss: 0.237600, Acc: 0.933299\n",
      "[28/50] Loss: 0.237980, Acc: 0.933177\n",
      "[28/50] Loss: 0.237188, Acc: 0.933187\n",
      "[28/50] Loss: 0.238918, Acc: 0.933299\n",
      "Finish 28 epoch, Loss: 0.238863, Acc: 0.933300\n",
      "Test Loss: 0.273398, Acc: 0.925500\n",
      "\n",
      "epoch 29\n",
      "**********\n",
      "[29/50] Loss: 0.240834, Acc: 0.930833\n",
      "[29/50] Loss: 0.239651, Acc: 0.931927\n",
      "[29/50] Loss: 0.239557, Acc: 0.932292\n",
      "[29/50] Loss: 0.235702, Acc: 0.933984\n",
      "[29/50] Loss: 0.233629, Acc: 0.934458\n",
      "[29/50] Loss: 0.238262, Acc: 0.933663\n",
      "Finish 29 epoch, Loss: 0.238726, Acc: 0.933467\n",
      "Test Loss: 0.282004, Acc: 0.922900\n",
      "\n",
      "epoch 30\n",
      "**********\n",
      "[30/50] Loss: 0.239467, Acc: 0.934375\n",
      "[30/50] Loss: 0.237115, Acc: 0.933177\n",
      "[30/50] Loss: 0.234092, Acc: 0.934653\n",
      "[30/50] Loss: 0.237688, Acc: 0.934193\n",
      "[30/50] Loss: 0.238992, Acc: 0.933750\n",
      "[30/50] Loss: 0.238732, Acc: 0.934063\n",
      "Finish 30 epoch, Loss: 0.239146, Acc: 0.934100\n",
      "Test Loss: 0.273664, Acc: 0.925400\n",
      "\n",
      "epoch 31\n",
      "**********\n",
      "[31/50] Loss: 0.236406, Acc: 0.935000\n",
      "[31/50] Loss: 0.237801, Acc: 0.934427\n",
      "[31/50] Loss: 0.243776, Acc: 0.932604\n",
      "[31/50] Loss: 0.239872, Acc: 0.933490\n",
      "[31/50] Loss: 0.239911, Acc: 0.934333\n",
      "[31/50] Loss: 0.239737, Acc: 0.933854\n",
      "Finish 31 epoch, Loss: 0.238764, Acc: 0.934067\n",
      "Test Loss: 0.274157, Acc: 0.926200\n",
      "\n",
      "epoch 32\n",
      "**********\n",
      "[32/50] Loss: 0.245586, Acc: 0.933333\n",
      "[32/50] Loss: 0.235432, Acc: 0.934844\n",
      "[32/50] Loss: 0.236850, Acc: 0.934375\n",
      "[32/50] Loss: 0.238449, Acc: 0.934089\n",
      "[32/50] Loss: 0.238922, Acc: 0.933729\n",
      "[32/50] Loss: 0.237821, Acc: 0.933733\n",
      "Finish 32 epoch, Loss: 0.238659, Acc: 0.933717\n",
      "Test Loss: 0.277030, Acc: 0.926300\n",
      "\n",
      "epoch 33\n",
      "**********\n",
      "[33/50] Loss: 0.247397, Acc: 0.932604\n",
      "[33/50] Loss: 0.237453, Acc: 0.934688\n",
      "[33/50] Loss: 0.235277, Acc: 0.934340\n",
      "[33/50] Loss: 0.236303, Acc: 0.933464\n",
      "[33/50] Loss: 0.237206, Acc: 0.933375\n",
      "[33/50] Loss: 0.237466, Acc: 0.933663\n",
      "Finish 33 epoch, Loss: 0.238454, Acc: 0.933500\n",
      "Test Loss: 0.280515, Acc: 0.923900\n",
      "\n",
      "epoch 34\n",
      "**********\n",
      "[34/50] Loss: 0.231190, Acc: 0.934271\n",
      "[34/50] Loss: 0.238608, Acc: 0.933021\n",
      "[34/50] Loss: 0.238793, Acc: 0.932951\n",
      "[34/50] Loss: 0.237072, Acc: 0.933958\n",
      "[34/50] Loss: 0.237608, Acc: 0.934229\n",
      "[34/50] Loss: 0.237547, Acc: 0.934236\n",
      "Finish 34 epoch, Loss: 0.238239, Acc: 0.933983\n",
      "Test Loss: 0.276444, Acc: 0.925200\n",
      "\n",
      "epoch 35\n",
      "**********\n",
      "[35/50] Loss: 0.239345, Acc: 0.935521\n",
      "[35/50] Loss: 0.239363, Acc: 0.935000\n",
      "[35/50] Loss: 0.238488, Acc: 0.933958\n",
      "[35/50] Loss: 0.237798, Acc: 0.934089\n",
      "[35/50] Loss: 0.239870, Acc: 0.934042\n",
      "[35/50] Loss: 0.238616, Acc: 0.934497\n",
      "Finish 35 epoch, Loss: 0.238201, Acc: 0.934383\n",
      "Test Loss: 0.271977, Acc: 0.927000\n",
      "\n",
      "epoch 36\n",
      "**********\n",
      "[36/50] Loss: 0.218389, Acc: 0.939896\n",
      "[36/50] Loss: 0.233918, Acc: 0.935312\n",
      "[36/50] Loss: 0.235421, Acc: 0.934861\n",
      "[36/50] Loss: 0.237327, Acc: 0.934818\n",
      "[36/50] Loss: 0.236958, Acc: 0.934542\n",
      "[36/50] Loss: 0.238259, Acc: 0.934653\n",
      "Finish 36 epoch, Loss: 0.237998, Acc: 0.934717\n",
      "Test Loss: 0.277413, Acc: 0.924800\n",
      "\n",
      "epoch 37\n",
      "**********\n",
      "[37/50] Loss: 0.243919, Acc: 0.936667\n",
      "[37/50] Loss: 0.245102, Acc: 0.934844\n",
      "[37/50] Loss: 0.241544, Acc: 0.934583\n",
      "[37/50] Loss: 0.238824, Acc: 0.934609\n",
      "[37/50] Loss: 0.238787, Acc: 0.934250\n",
      "[37/50] Loss: 0.238458, Acc: 0.934236\n",
      "Finish 37 epoch, Loss: 0.237726, Acc: 0.934317\n",
      "Test Loss: 0.276269, Acc: 0.926200\n",
      "\n",
      "epoch 38\n",
      "**********\n",
      "[38/50] Loss: 0.237794, Acc: 0.937187\n",
      "[38/50] Loss: 0.230616, Acc: 0.938698\n",
      "[38/50] Loss: 0.228859, Acc: 0.937569\n",
      "[38/50] Loss: 0.232442, Acc: 0.936771\n",
      "[38/50] Loss: 0.233490, Acc: 0.935729\n",
      "[38/50] Loss: 0.237033, Acc: 0.934288\n",
      "Finish 38 epoch, Loss: 0.237845, Acc: 0.934183\n",
      "Test Loss: 0.277273, Acc: 0.924100\n",
      "\n",
      "epoch 39\n",
      "**********\n",
      "[39/50] Loss: 0.213835, Acc: 0.942708\n",
      "[39/50] Loss: 0.225120, Acc: 0.938906\n",
      "[39/50] Loss: 0.230144, Acc: 0.936493\n",
      "[39/50] Loss: 0.237851, Acc: 0.933984\n",
      "[39/50] Loss: 0.237744, Acc: 0.933937\n",
      "[39/50] Loss: 0.237772, Acc: 0.934115\n",
      "Finish 39 epoch, Loss: 0.237948, Acc: 0.934033\n",
      "Test Loss: 0.279371, Acc: 0.924200\n",
      "\n",
      "epoch 40\n",
      "**********\n",
      "[40/50] Loss: 0.229580, Acc: 0.938542\n",
      "[40/50] Loss: 0.234238, Acc: 0.936927\n",
      "[40/50] Loss: 0.235113, Acc: 0.936250\n",
      "[40/50] Loss: 0.235837, Acc: 0.936068\n",
      "[40/50] Loss: 0.236059, Acc: 0.935583\n",
      "[40/50] Loss: 0.237353, Acc: 0.934774\n",
      "Finish 40 epoch, Loss: 0.237527, Acc: 0.934683\n",
      "Test Loss: 0.281774, Acc: 0.923900\n",
      "\n",
      "epoch 41\n",
      "**********\n",
      "[41/50] Loss: 0.226616, Acc: 0.936771\n",
      "[41/50] Loss: 0.223708, Acc: 0.936875\n",
      "[41/50] Loss: 0.230148, Acc: 0.935174\n",
      "[41/50] Loss: 0.231094, Acc: 0.935260\n",
      "[41/50] Loss: 0.232580, Acc: 0.935438\n",
      "[41/50] Loss: 0.236936, Acc: 0.934306\n",
      "Finish 41 epoch, Loss: 0.237018, Acc: 0.934083\n",
      "Test Loss: 0.277838, Acc: 0.923800\n",
      "\n",
      "epoch 42\n",
      "**********\n",
      "[42/50] Loss: 0.234163, Acc: 0.936562\n",
      "[42/50] Loss: 0.240116, Acc: 0.933698\n",
      "[42/50] Loss: 0.236684, Acc: 0.934097\n",
      "[42/50] Loss: 0.233922, Acc: 0.934870\n",
      "[42/50] Loss: 0.234461, Acc: 0.934875\n",
      "[42/50] Loss: 0.236923, Acc: 0.934427\n",
      "Finish 42 epoch, Loss: 0.237348, Acc: 0.934600\n",
      "Test Loss: 0.274519, Acc: 0.926400\n",
      "\n",
      "epoch 43\n",
      "**********\n",
      "[43/50] Loss: 0.235698, Acc: 0.935312\n",
      "[43/50] Loss: 0.234093, Acc: 0.934375\n",
      "[43/50] Loss: 0.231536, Acc: 0.935590\n",
      "[43/50] Loss: 0.236796, Acc: 0.934922\n",
      "[43/50] Loss: 0.233334, Acc: 0.935417\n",
      "[43/50] Loss: 0.236946, Acc: 0.934913\n",
      "Finish 43 epoch, Loss: 0.237254, Acc: 0.934583\n",
      "Test Loss: 0.273763, Acc: 0.927300\n",
      "\n",
      "epoch 44\n",
      "**********\n",
      "[44/50] Loss: 0.226809, Acc: 0.937917\n",
      "[44/50] Loss: 0.234382, Acc: 0.937031\n",
      "[44/50] Loss: 0.235503, Acc: 0.936181\n",
      "[44/50] Loss: 0.233727, Acc: 0.935781\n",
      "[44/50] Loss: 0.236042, Acc: 0.935146\n",
      "[44/50] Loss: 0.236564, Acc: 0.934757\n",
      "Finish 44 epoch, Loss: 0.236506, Acc: 0.934733\n",
      "Test Loss: 0.282492, Acc: 0.924100\n",
      "\n",
      "epoch 45\n",
      "**********\n",
      "[45/50] Loss: 0.243187, Acc: 0.933958\n",
      "[45/50] Loss: 0.237847, Acc: 0.934479\n",
      "[45/50] Loss: 0.239464, Acc: 0.934340\n",
      "[45/50] Loss: 0.238532, Acc: 0.933620\n",
      "[45/50] Loss: 0.238376, Acc: 0.933896\n",
      "[45/50] Loss: 0.235923, Acc: 0.934358\n",
      "Finish 45 epoch, Loss: 0.237249, Acc: 0.934383\n",
      "Test Loss: 0.272878, Acc: 0.925200\n",
      "\n",
      "epoch 46\n",
      "**********\n",
      "[46/50] Loss: 0.231703, Acc: 0.934896\n",
      "[46/50] Loss: 0.233741, Acc: 0.935521\n",
      "[46/50] Loss: 0.231284, Acc: 0.936493\n",
      "[46/50] Loss: 0.230816, Acc: 0.936823\n",
      "[46/50] Loss: 0.232317, Acc: 0.935896\n",
      "[46/50] Loss: 0.235854, Acc: 0.934878\n",
      "Finish 46 epoch, Loss: 0.236717, Acc: 0.934583\n",
      "Test Loss: 0.276696, Acc: 0.925600\n",
      "\n",
      "epoch 47\n",
      "**********\n",
      "[47/50] Loss: 0.235621, Acc: 0.934167\n",
      "[47/50] Loss: 0.234408, Acc: 0.935052\n",
      "[47/50] Loss: 0.232424, Acc: 0.934444\n",
      "[47/50] Loss: 0.237262, Acc: 0.934375\n",
      "[47/50] Loss: 0.238993, Acc: 0.933625\n",
      "[47/50] Loss: 0.236633, Acc: 0.934358\n",
      "Finish 47 epoch, Loss: 0.236651, Acc: 0.934283\n",
      "Test Loss: 0.276666, Acc: 0.925200\n",
      "\n",
      "epoch 48\n",
      "**********\n",
      "[48/50] Loss: 0.246743, Acc: 0.933854\n",
      "[48/50] Loss: 0.244640, Acc: 0.932760\n",
      "[48/50] Loss: 0.239653, Acc: 0.932639\n",
      "[48/50] Loss: 0.238831, Acc: 0.932786\n",
      "[48/50] Loss: 0.235160, Acc: 0.934417\n",
      "[48/50] Loss: 0.235599, Acc: 0.934358\n",
      "Finish 48 epoch, Loss: 0.236751, Acc: 0.934267\n",
      "Test Loss: 0.275929, Acc: 0.924800\n",
      "\n",
      "epoch 49\n",
      "**********\n",
      "[49/50] Loss: 0.223388, Acc: 0.937187\n",
      "[49/50] Loss: 0.236084, Acc: 0.934479\n",
      "[49/50] Loss: 0.234933, Acc: 0.935104\n",
      "[49/50] Loss: 0.237610, Acc: 0.934974\n",
      "[49/50] Loss: 0.239555, Acc: 0.933833\n",
      "[49/50] Loss: 0.237292, Acc: 0.934462\n",
      "Finish 49 epoch, Loss: 0.237110, Acc: 0.934617\n",
      "Test Loss: 0.277119, Acc: 0.924200\n",
      "\n",
      "epoch 50\n",
      "**********\n",
      "[50/50] Loss: 0.234455, Acc: 0.933958\n",
      "[50/50] Loss: 0.234700, Acc: 0.934271\n",
      "[50/50] Loss: 0.236753, Acc: 0.933750\n",
      "[50/50] Loss: 0.236487, Acc: 0.933828\n",
      "[50/50] Loss: 0.238510, Acc: 0.934021\n",
      "[50/50] Loss: 0.236451, Acc: 0.934410\n",
      "Finish 50 epoch, Loss: 0.236551, Acc: 0.934250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.277231, Acc: 0.924700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoches):\n",
    "    print('epoch {}'.format(epoch + 1))\n",
    "    print('*' * 10)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for i, data in enumerate(train_loader, 1):\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if torch.cuda.is_available():\n",
    "            with torch.no_grad():\n",
    "                img = img.cuda()            \n",
    "                label = label.cuda()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                img = img            \n",
    "                label = label\n",
    "        # 向前传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        running_loss += loss.item() * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        running_acc += num_correct.item()\n",
    "        # 向后传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 300 == 0:\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "                running_acc / (batch_size * i)))\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_dataset)), running_acc / (len(\n",
    "            train_dataset))))\n",
    "    model.eval()\n",
    "    eval_loss = 0.\n",
    "    eval_acc = 0.\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if torch.cuda.is_available():\n",
    "            with torch.no_grad():\n",
    "                img = img.cuda()            \n",
    "                label = label.cuda()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                img = img            \n",
    "                label = label\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.item() * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        eval_acc += num_correct.item()\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "        test_dataset)), eval_acc / (len(test_dataset))))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
